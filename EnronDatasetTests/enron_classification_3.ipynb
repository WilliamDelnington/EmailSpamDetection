{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e685b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../Handlers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d09b1788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traintest import ClassificationModel, models, add_to_json_array\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "metric_results = []\n",
    "\n",
    "def t_and_e(model, X, y, dataset_name, mode, n_jobs, cv):\n",
    "    print(f\"Begin {model.__class__.__name__}\")\n",
    "    classification_model = ClassificationModel(model, dataset_name)\n",
    "    classification_model.train_with_finding_best_parameters(X, y, save_model=True, mode=mode, n_jobs=n_jobs, cv=cv)\n",
    "    classification_model.get_best_estimator(put_right_in_the_model=True)\n",
    "    print(f\"{model.__class__.__name__} classification report\")\n",
    "    metrics = classification_model.evaluate(detailed=True)\n",
    "    metric_results.append(metrics)\n",
    "    print(metrics)\n",
    "    print(\"\\n\")\n",
    "\n",
    "def train_and_evaluate_model(X, y, dataset_name, m=None, mode=\"grid\"):\n",
    "    print(f\"{dataset_name} classification report\")\n",
    "    print(\"=========================================\")\n",
    "\n",
    "    train_eval = partial(\n",
    "        t_and_e,\n",
    "        X=X,\n",
    "        y=y,\n",
    "        dataset_name=dataset_name,\n",
    "        mode=mode,\n",
    "        n_jobs=6,\n",
    "        cv=4\n",
    "    )\n",
    "\n",
    "    if m is None:\n",
    "        with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "            executor.map(train_eval, models)\n",
    "            # future = [executor.submit(train_eval, model) for model in models]\n",
    "        # for model in models:\n",
    "        #     train_eval(model)\n",
    "    else:\n",
    "        t_and_e(X, y, m, dataset_name, mode, n_jobs=6, cv=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7f8003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_enron = \"enron1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfcc96",
   "metadata": {},
   "source": [
    "## Stemming + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a08ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "enron1_stemmed_countvec = joblib.load(\"./preprocess/enron1_stemmed_countvec.pkl\")\n",
    "enron2_stemmed_countvec = joblib.load(\"./preprocess/enron2_stemmed_countvec.pkl\")\n",
    "enron3_stemmed_countvec = joblib.load(\"./preprocess/enron3_stemmed_countvec.pkl\")\n",
    "enron4_stemmed_countvec = joblib.load(\"./preprocess/enron4_stemmed_countvec.pkl\")\n",
    "enron5_stemmed_countvec = joblib.load(\"./preprocess/enron5_stemmed_countvec.pkl\")\n",
    "enron6_stemmed_countvec = joblib.load(\"./preprocess/enron6_stemmed_countvec.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ef3934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_stemmed_countvec_X, enron1_y = enron1_stemmed_countvec[\"features\"], enron1_stemmed_countvec[\"labels\"]\n",
    "enron2_stemmed_countvec_X, enron2_y = enron2_stemmed_countvec[\"features\"], enron2_stemmed_countvec[\"labels\"]\n",
    "enron3_stemmed_countvec_X, enron3_y = enron3_stemmed_countvec[\"features\"], enron3_stemmed_countvec[\"labels\"]\n",
    "enron4_stemmed_countvec_X, enron4_y = enron4_stemmed_countvec[\"features\"], enron4_stemmed_countvec[\"labels\"]\n",
    "enron5_stemmed_countvec_X, enron5_y = enron5_stemmed_countvec[\"features\"], enron5_stemmed_countvec[\"labels\"]\n",
    "enron6_stemmed_countvec_X, enron6_y = enron6_stemmed_countvec[\"features\"], enron6_stemmed_countvec[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "284c5066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1_stemmed_countvec classification report\n",
      "=========================================\n",
      "Begin SVC\n",
      "Begin MultinomialNB\n",
      "Begin BernoulliNB\n",
      "The best estimator for Bernoulli Naive Bayes of dataset enron1_stemmed_countvec is: \n",
      "The best estimator for Multinomial Naive Bayes of dataset enron1_stemmed_countvec is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "MultinomialNB(alpha=0.1)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9729468599033816, 'weighted_precision': 0.9748277259219852, 'wighted_recall': 0.9729468599033816, 'weighted_f1': 0.9732713113390702, 'macro_precision': 0.9566852057842047, 'macro_recall': 0.9791470212030959, 'macro_f1': 0.9670121023922487, 'roc_auc': 0.979147021203096}, 'confusion_matrix': array([[723,  26],\n",
      "       [  2, 284]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': True}, 'best_score': 0.9649503826423345}\n",
      "\n",
      "\n",
      "Begin RandomForestClassifier\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.927536231884058, 'weighted_precision': 0.9268352325524527, 'wighted_recall': 0.927536231884058, 'weighted_f1': 0.9270053536173443, 'macro_precision': 0.9143520521473277, 'macro_recall': 0.9023826640649071, 'macro_f1': 0.9080979199643876, 'roc_auc': 0.9023826640649071}, 'confusion_matrix': array([[718,  31],\n",
      "       [ 44, 242]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9303829226585932}\n",
      "\n",
      "\n",
      "Begin DecisionTreeClassifier\n",
      "The best estimator for SVM of dataset enron1_stemmed_countvec is: \n",
      "SVC(C=0.1, kernel='linear')\n",
      "SVC classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.966183574879227, 'weighted_precision': 0.9671898429981209, 'wighted_recall': 0.966183574879227, 'weighted_f1': 0.9664446212834051, 'macro_precision': 0.9516597716965247, 'macro_recall': 0.9658285639594051, 'macro_f1': 0.9583869889411054, 'roc_auc': 0.9658285639594051}, 'confusion_matrix': array([[724,  25],\n",
      "       [ 10, 276]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.969783636550519}\n",
      "\n",
      "\n",
      "Begin AdaBoostClassifier\n",
      "The best estimator for AdaBoost of dataset enron1_stemmed_countvec is: \n",
      "AdaBoostClassifier(n_estimators=200)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9690821256038648, 'weighted_precision': 0.969482766213724, 'wighted_recall': 0.9690821256038648, 'weighted_f1': 0.9692123513187477, 'macro_precision': 0.9578892285659203, 'macro_recall': 0.9656698441745171, 'macro_f1': 0.9616755380698913, 'roc_auc': 0.9656698441745171}, 'confusion_matrix': array([[729,  20],\n",
      "       [ 12, 274]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9562470215569199}\n",
      "\n",
      "\n",
      "Begin LogisticRegression\n",
      "The best estimator for Decision Tree of dataset enron1_stemmed_countvec is: \n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=30, min_samples_split=10)\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9314009661835749, 'weighted_precision': 0.9320095206008518, 'wighted_recall': 0.9314009661835749, 'weighted_f1': 0.9316546102308662, 'macro_precision': 0.91188375665805, 'macro_recall': 0.9180212311053433, 'macro_f1': 0.9148778682457439, 'roc_auc': 0.9180212311053433}, 'confusion_matrix': array([[710,  39],\n",
      "       [ 32, 254]], dtype=int64), 'best_parameters': {'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'entropy'}, 'best_score': 0.9272432932469936}\n",
      "\n",
      "\n",
      "Begin KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97195848 0.97244204 0.92265088 0.90597184        nan        nan\n",
      "        nan        nan 0.97195965        nan 0.92216709 0.90669718\n",
      " 0.97389249 0.97461759 0.92265065 0.90621362        nan        nan\n",
      "        nan        nan 0.97195965        nan 0.92240887 0.9064554\n",
      " 0.97195848 0.97195848 0.92289243 0.90621362        nan        nan\n",
      "        nan        nan 0.97195965        nan 0.92313421 0.9064554 ]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.93298776 0.93444067 0.94019988 0.95064923        nan        nan\n",
      "        nan        nan 0.94592816        nan 0.94006415 0.95166363\n",
      " 0.93892085 0.94186086 0.94018955 0.95071806        nan        nan\n",
      "        nan        nan 0.94592816        nan 0.94012062 0.95191659\n",
      " 0.94282503 0.94282503 0.94025795 0.95071806        nan        nan\n",
      "        nan        nan 0.94592816        nan 0.94031393 0.95159541]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97445773 0.97445773 0.78673246 0.71754223        nan        nan\n",
      "        nan        nan 0.95963881        nan 0.78508229 0.7191924\n",
      " 0.9744523  0.97362993 0.78672974 0.71836731        nan        nan\n",
      "        nan        nan 0.95963881        nan 0.78590466 0.71837003\n",
      " 0.96291471 0.96291471 0.78755482 0.71836731        nan        nan\n",
      "        nan        nan 0.95963881        nan 0.78837719 0.71836731]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.95325473 0.95401436 0.85541073 0.81565792        nan        nan\n",
      "        nan        nan 0.95262946        nan 0.85435699 0.81717801\n",
      " 0.95631776 0.95744165 0.85542459 0.81622538        nan        nan\n",
      "        nan        nan 0.95262946        nan 0.85491004 0.8165707\n",
      " 0.95268905 0.95268905 0.8559373  0.81622538        nan        nan\n",
      "        nan        nan 0.95262946        nan 0.85648829 0.81661269]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset enron1_stemmed_countvec is: \n",
      "LogisticRegression(C=1, solver='liblinear')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.970048309178744, 'weighted_precision': 0.9709977697232596, 'wighted_recall': 0.970048309178744, 'weighted_f1': 0.9702795217081589, 'macro_precision': 0.9563444286529008, 'macro_recall': 0.9706601809405547, 'macro_f1': 0.9631427616335504, 'roc_auc': 0.9706601809405547}, 'confusion_matrix': array([[726,  23],\n",
      "       [  8, 278]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9746175912688401}\n",
      "\n",
      "\n",
      "Begin SGDClassifier\n",
      "The best estimator for K-nearest Neighbors of dataset enron1_stemmed_countvec is: \n",
      "KNeighborsClassifier(weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.8927536231884058, 'weighted_precision': 0.9101366930171279, 'wighted_recall': 0.8927536231884058, 'weighted_f1': 0.8962100063769568, 'macro_precision': 0.8578746064541519, 'macro_recall': 0.9075293865013492, 'macro_f1': 0.8754268191522929, 'roc_auc': 0.9075293865013491}, 'confusion_matrix': array([[655,  94],\n",
      "       [ 17, 269]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}, 'best_score': 0.8767270297797587}\n",
      "\n",
      "\n",
      "Begin HistGradientBoostingClassifier\n",
      "The best estimator for Random Forest of dataset enron1_stemmed_countvec is: \n",
      "RandomForestClassifier(min_samples_split=5)\n",
      "RandomForestClassifier classification report\n",
      "Begin Perceptron\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9768115942028985, 'weighted_precision': 0.9768703639032781, 'wighted_recall': 0.9768115942028985, 'weighted_f1': 0.9768364918511508, 'macro_precision': 0.9700677710843374, 'macro_recall': 0.9720909931190305, 'macro_f1': 0.9710726862807207, 'roc_auc': 0.9720909931190306}, 'confusion_matrix': array([[736,  13],\n",
      "       [ 11, 275]], dtype=int64), 'best_parameters': {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9722014315215056}\n",
      "\n",
      "\n",
      "The best estimator for Perceptron of dataset enron1_stemmed_countvec is: \n",
      "Perceptron(penalty='l2')\n",
      "Perceptron classification report\n",
      "{'dataset': 'enron1_stemmed_countvec', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9400966183574879, 'weighted_precision': 0.9399748329482353, 'wighted_recall': 0.9400966183574879, 'weighted_f1': 0.9400314602932451, 'macro_precision': 0.9258781718272351, 'macro_recall': 0.9240292417862511, 'macro_f1': 0.9249473684210525, 'roc_auc': 0.9240292417862511}, 'confusion_matrix': array([[719,  30],\n",
      "       [ 32, 254]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}, 'best_score': 0.96059811809118}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_stemmed_countvec_X, enron1_y, \"enron1_stemmed_countvec\")\n",
    "\n",
    "enron1_stemmed_countvec_X = None\n",
    "enron1_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22acb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron2_stemmed_countvec classification report\n",
      "=========================================\n",
      "Begin SVC\n",
      "Begin MultinomialNB\n",
      "Begin BernoulliNB\n",
      "The best estimator for Multinomial Naive Bayes of dataset enron2_stemmed_countvec is: \n",
      "MultinomialNB(alpha=0.1)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9906143344709898, 'weighted_precision': 0.9907073881518728, 'wighted_recall': 0.9906143344709898, 'weighted_f1': 0.9906380915884042, 'macro_precision': 0.9855894357033006, 'macro_recall': 0.9905310881312763, 'macro_f1': 0.9880248086728178, 'roc_auc': 0.9905310881312762}, 'confusion_matrix': array([[853,   8],\n",
      "       [  3, 308]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': True}, 'best_score': 0.9878329175203947}\n",
      "\n",
      "\n",
      "Begin RandomForestClassifier\n",
      "The best estimator for Bernoulli Naive Bayes of dataset enron2_stemmed_countvec is: \n",
      "BernoulliNB()\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9709897610921502, 'weighted_precision': 0.9733302449665505, 'wighted_recall': 0.9709897610921502, 'weighted_f1': 0.9713999915949154, 'macro_precision': 0.9518758094512141, 'macro_recall': 0.9782015229431118, 'macro_f1': 0.9638790990442211, 'roc_auc': 0.9782015229431118}, 'confusion_matrix': array([[829,  32],\n",
      "       [  2, 309]], dtype=int64), 'best_parameters': {'alpha': 1.0, 'fit_prior': True}, 'best_score': 0.9739582574328992}\n",
      "\n",
      "\n",
      "Begin DecisionTreeClassifier\n",
      "The best estimator for SVM of dataset enron2_stemmed_countvec is: \n",
      "SVC(C=0.1, kernel='linear')\n",
      "SVC classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9837883959044369, 'weighted_precision': 0.9839155166956094, 'wighted_recall': 0.9837883959044369, 'weighted_f1': 0.9838294309254254, 'macro_precision': 0.9769238731811192, 'macro_recall': 0.981777339592413, 'macro_f1': 0.9793155786166852, 'roc_auc': 0.981777339592413}, 'confusion_matrix': array([[849,  12],\n",
      "       [  7, 304]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9850586048504385}\n",
      "\n",
      "\n",
      "Begin AdaBoostClassifier\n",
      "The best estimator for AdaBoost of dataset enron2_stemmed_countvec is: \n",
      "AdaBoostClassifier(n_estimators=200)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.985494880546075, 'weighted_precision': 0.9856852963624904, 'wighted_recall': 0.985494880546075, 'weighted_f1': 0.985545990372904, 'macro_precision': 0.978204675003314, 'macro_recall': 0.9849927736760142, 'macro_f1': 0.9815302182649122, 'roc_auc': 0.9849927736760141}, 'confusion_matrix': array([[849,  12],\n",
      "       [  5, 306]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9773739591318058}\n",
      "\n",
      "\n",
      "Begin LogisticRegression\n",
      "The best estimator for Decision Tree of dataset enron2_stemmed_countvec is: \n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=30, min_samples_split=5)\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9479522184300341, 'weighted_precision': 0.9476000294611187, 'wighted_recall': 0.9479522184300341, 'weighted_f1': 0.9477054446587051, 'macro_precision': 0.9368386998553704, 'macro_recall': 0.9286311811211819, 'macro_f1': 0.9326248252997118, 'roc_auc': 0.9286311811211819}, 'confusion_matrix': array([[835,  26],\n",
      "       [ 35, 276]], dtype=int64), 'best_parameters': {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'entropy'}, 'best_score': 0.9494147894364083}\n",
      "\n",
      "\n",
      "Begin KNeighborsClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.98890093 0.98911442 0.98057635 0.97481369        nan        nan\n",
      "        nan        nan 0.98399169        nan 0.98057635 0.9748135\n",
      " 0.98826081 0.98847431 0.98036286 0.975027          nan        nan\n",
      "        nan        nan 0.98399169        nan 0.98057635 0.97438688\n",
      " 0.98569963 0.98591294 0.98057635 0.97524049        nan        nan\n",
      "        nan        nan 0.98399169        nan 0.98014936 0.97460019]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97170737 0.97252665 0.96701089 0.96866379        nan        nan\n",
      "        nan        nan 0.97044001        nan 0.96701089 0.96789188\n",
      " 0.96850915 0.9693231  0.96698986 0.9686698         nan        nan\n",
      "        nan        nan 0.97044001        nan 0.96619654 0.9669801\n",
      " 0.96509911 0.96513212 0.96701671 0.96870908        nan        nan\n",
      "        nan        nan 0.97044001        nan 0.96614583 0.96785056]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.98481436 0.98481436 0.95612658 0.93081434        nan        nan\n",
      "        nan        nan 0.9662475         nan 0.95612658 0.93165609\n",
      " 0.9856618  0.9856618  0.95528199 0.93165609        nan        nan\n",
      "        nan        nan 0.9662475         nan 0.95697118 0.93081434\n",
      " 0.97890789 0.97974964 0.95612658 0.93250068        nan        nan\n",
      "        nan        nan 0.9662475         nan 0.95528199 0.93081434]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97820748 0.97862057 0.96137661 0.94912887        nan        nan\n",
      "        nan        nan 0.96828388        nan 0.96137661 0.94918438\n",
      " 0.97699888 0.97741202 0.96093316 0.94960989        nan        nan\n",
      "        nan        nan 0.96828388        nan 0.96141015 0.94834156\n",
      " 0.97194851 0.97237983 0.96137801 0.95004845        nan        nan\n",
      "        nan        nan 0.96828388        nan 0.96052191 0.94875077]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset enron2_stemmed_countvec is: \n",
      "LogisticRegression(C=0.1, solver='liblinear')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9880546075085325, 'weighted_precision': 0.9880863041626414, 'wighted_recall': 0.9880546075085325, 'weighted_f1': 0.9880668057700956, 'macro_precision': 0.9837280142226454, 'macro_recall': 0.9857079370058743, 'macro_f1': 0.9847122838401908, 'roc_auc': 0.9857079370058744}, 'confusion_matrix': array([[853,   8],\n",
      "       [  6, 305]], dtype=int64), 'best_parameters': {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9891144204510015}\n",
      "\n",
      "\n",
      "Begin SGDClassifier\n",
      "The best estimator for Random Forest of dataset enron2_stemmed_countvec is: \n",
      "RandomForestClassifier(min_samples_split=10)\n",
      "RandomForestClassifier classification report\n",
      "The best estimator for K-nearest Neighbors of dataset enron2_stemmed_countvec is: \n",
      "KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9812286689419796, 'weighted_precision': 0.9813856010201112, 'wighted_recall': 0.9812286689419796, 'weighted_f1': 0.9810672668770313, 'macro_precision': 0.9840828711130007, 'macro_recall': 0.9677112159270422, 'macro_f1': 0.9755190708944312, 'roc_auc': 0.9677112159270421}, 'confusion_matrix': array([[858,   3],\n",
      "       [ 19, 292]], dtype=int64), 'best_parameters': {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9792963046082371}\n",
      "\n",
      "\n",
      "Begin HistGradientBoostingClassifier\n",
      "{'dataset': 'enron2_stemmed_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.9274744027303754, 'weighted_precision': 0.9320887050179142, 'wighted_recall': 0.9274744027303754, 'weighted_f1': 0.9287141269431921, 'macro_precision': 0.8977932150429639, 'macro_recall': 0.9259908653289565, 'macro_f1': 0.9102857940499725, 'roc_auc': 0.9259908653289565}, 'confusion_matrix': array([[800,  61],\n",
      "       [ 24, 287]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}, 'best_score': 0.922732204323483}\n",
      "\n",
      "\n",
      "Begin Perceptron\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron2_stemmed_countvec_X, enron2_y, \"enron2_stemmed_countvec\")\n",
    "enron2_stemmed_countvec_X = None\n",
    "enron2_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffbe30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron3_stemmed_countvec_X, enron3_y, \"enron3_stemmed_countvec\")\n",
    "enron3_stemmed_countvec_X = None\n",
    "enron3_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc70504",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron4_stemmed_countvec_X, enron4_y, \"enron4_stemmed_countvec\")\n",
    "enron4_stemmed_countvec_X = None\n",
    "enron4_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43da967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron5_stemmed_countvec_X, enron5_y, \"enron5_stemmed_countvec\")\n",
    "enron5_stemmed_countvec_X = None\n",
    "enron5_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8c3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron6_stemmed_countvec_X, enron6_y, \"enron6_stemmed_countvec\")\n",
    "enron6_stemmed_countvec_X = None\n",
    "enron6_y = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4b4d06",
   "metadata": {},
   "source": [
    "## Stemming + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_stemmed_tfidf = joblib.load(\"./preprocess/enron1_stemmed_tfidf.pkl\")\n",
    "enron2_stemmed_tfidf = joblib.load(\"./preprocess/enron2_stemmed_tfidf.pkl\")\n",
    "enron3_stemmed_tfidf = joblib.load(\"./preprocess/enron3_stemmed_tfidf.pkl\")\n",
    "enron4_stemmed_tfidf = joblib.load(\"./preprocess/enron4_stemmed_tfidf.pkl\")\n",
    "enron5_stemmed_tfidf = joblib.load(\"./preprocess/enron5_stemmed_tfidf.pkl\")\n",
    "enron6_stemmed_tfidf = joblib.load(\"./preprocess/enron6_stemmed_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_stemmed_tfidf_X, enron1_y = enron1_stemmed_tfidf[\"features\"], enron1_stemmed_tfidf[\"labels\"]\n",
    "enron2_stemmed_tfidf_X, enron2_y = enron2_stemmed_tfidf[\"features\"], enron2_stemmed_tfidf[\"labels\"]\n",
    "enron3_stemmed_tfidf_X, enron3_y = enron3_stemmed_tfidf[\"features\"], enron3_stemmed_tfidf[\"labels\"]\n",
    "enron4_stemmed_tfidf_X, enron4_y = enron4_stemmed_tfidf[\"features\"], enron4_stemmed_tfidf[\"labels\"]\n",
    "enron5_stemmed_tfidf_X, enron5_y = enron5_stemmed_tfidf[\"features\"], enron5_stemmed_tfidf[\"labels\"]\n",
    "enron6_stemmed_tfidf_X, enron6_y = enron6_stemmed_tfidf[\"features\"], enron6_stemmed_tfidf[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b247eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1_stemmed_tfidf classification report\n",
      "=========================================\n",
      "Executing\n",
      "Executing\n",
      "The best estimator for Multinomial Naive Bayes of dataset enron1_stemmed_tfidf is: \n",
      "MultinomialNB(alpha=0.5)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9729468599033816, 'weighted_precision': 0.9737648953301128, 'wighted_recall': 0.9729468599033816, 'weighted_f1': 0.9731424111285633, 'macro_precision': 0.9602380952380953, 'macro_recall': 0.9737435461734527, 'macro_f1': 0.9666752527529139, 'roc_auc': 0.9737435461734526}, 'confusion_matrix': array([[728,  21],\n",
      "       [  7, 279]], dtype=int64), 'best_parameters': {'alpha': 0.5, 'fit_prior': True}, 'best_score': 0.9714767938403461}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for Bernoulli Naive Bayes of dataset enron1_stemmed_tfidf is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.927536231884058, 'weighted_precision': 0.9268352325524527, 'wighted_recall': 0.927536231884058, 'weighted_f1': 0.9270053536173443, 'macro_precision': 0.9143520521473277, 'macro_recall': 0.9023826640649071, 'macro_f1': 0.9080979199643876, 'roc_auc': 0.9023826640649071}, 'confusion_matrix': array([[718,  31],\n",
      "       [ 44, 242]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9303829226585932}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for SVM of dataset enron1_stemmed_tfidf is: \n",
      "SVC(C=10)\n",
      "SVC classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9816425120772947, 'weighted_precision': 0.9822634425540853, 'wighted_recall': 0.9816425120772947, 'weighted_f1': 0.9817661315245856, 'macro_precision': 0.9712061036789298, 'macro_recall': 0.9840743368780751, 'macro_f1': 0.9773633773633774, 'roc_auc': 0.9840743368780752}, 'confusion_matrix': array([[733,  16],\n",
      "       [  3, 283]], dtype=int64), 'best_parameters': {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, 'best_score': 0.984771162130089}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for Random Forest of dataset enron1_stemmed_tfidf is: \n",
      "RandomForestClassifier(min_samples_split=5)\n",
      "RandomForestClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9748792270531401, 'weighted_precision': 0.9751188535478998, 'wighted_recall': 0.9748792270531401, 'weighted_f1': 0.9749591007502516, 'macro_precision': 0.9658732646250853, 'macro_recall': 0.9718365746403129, 'macro_f1': 0.9687955137898085, 'roc_auc': 0.9718365746403129}, 'confusion_matrix': array([[733,  16],\n",
      "       [ 10, 276]], dtype=int64), 'best_parameters': {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9726852241190818}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for Decision Tree of dataset enron1_stemmed_tfidf is: \n",
      "DecisionTreeClassifier(criterion='entropy')\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9449275362318841, 'weighted_precision': 0.9449889972377652, 'wighted_recall': 0.9449275362318841, 'weighted_f1': 0.944957198206515, 'macro_precision': 0.9307607743762694, 'macro_recall': 0.9316898055215812, 'macro_f1': 0.9312237039524075, 'roc_auc': 0.9316898055215812}, 'confusion_matrix': array([[720,  29],\n",
      "       [ 28, 258]], dtype=int64), 'best_parameters': {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}, 'best_score': 0.9226490155953616}\n",
      "\n",
      "\n",
      "Executing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.86704767 0.86994903 0.86704767 0.86825657        nan        nan\n",
      "        nan        nan 0.97945365        nan 0.98477069 0.98259538\n",
      " 0.97872761 0.97848583 0.97872761 0.97848583        nan        nan\n",
      "        nan        nan 0.97945365        nan 0.98235383 0.98283693\n",
      " 0.98380428 0.9835625  0.9835625  0.98332072        nan        nan\n",
      "        nan        nan 0.97945365        nan 0.98307894 0.98187004]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.97296084 0.97200245 0.97296084 0.97315854        nan        nan\n",
      "        nan        nan 0.95443952        nan 0.96984385 0.96504972\n",
      " 0.95569673 0.95567148 0.95569673 0.95567148        nan        nan\n",
      "        nan        nan 0.95443952        nan 0.96578668 0.96656226\n",
      " 0.96445161 0.96364838 0.96364838 0.96361949        nan        nan\n",
      "        nan        nan 0.95443952        nan 0.96436736 0.96419011]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.56257328 0.57329392 0.56257328 0.56669869        nan        nan\n",
      "        nan        nan 0.97693026        nan 0.97857771 0.97610518\n",
      " 0.97279942 0.97197434 0.97279942 0.97197434        nan        nan\n",
      "        nan        nan 0.97693026        nan 0.97445773 0.97528552\n",
      " 0.98104482 0.98104482 0.98104482 0.98022245        nan        nan\n",
      "        nan        nan 0.97693026        nan 0.97857771 0.97445773]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.71160708 0.72013585 0.71160708 0.71501544        nan        nan\n",
      "        nan        nan 0.96542084        nan 0.97414065 0.97050943\n",
      " 0.96404441 0.96361323 0.96404441 0.96361323        nan        nan\n",
      "        nan        nan 0.96542084        nan 0.97005123 0.97086899\n",
      " 0.97263099 0.97223004 0.97223004 0.97181022        nan        nan\n",
      "        nan        nan 0.96542084        nan 0.97137158 0.96926033]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset enron1_stemmed_tfidf is: \n",
      "LogisticRegression(C=0.1, penalty=None, solver='sag')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9806763285024155, 'weighted_precision': 0.9811005775440675, 'wighted_recall': 0.9806763285024155, 'weighted_f1': 0.9807774077340742, 'macro_precision': 0.9712792122298212, 'macro_recall': 0.9812453901238948, 'macro_f1': 0.9760974393082806, 'roc_auc': 0.9812453901238948}, 'confusion_matrix': array([[734,  15],\n",
      "       [  5, 281]], dtype=int64), 'best_parameters': {'C': 0.1, 'penalty': None, 'solver': 'sag'}, 'best_score': 0.9847706949233315}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for AdaBoost of dataset enron1_stemmed_tfidf is: \n",
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=200)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9603864734299516, 'weighted_precision': 0.9626825990580178, 'wighted_recall': 0.9603864734299516, 'weighted_f1': 0.9608797387108049, 'macro_precision': 0.9414204757421257, 'macro_recall': 0.9639846135173238, 'macro_f1': 0.9517444657094023, 'roc_auc': 0.9639846135173239}, 'confusion_matrix': array([[716,  33],\n",
      "       [  8, 278]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'n_estimators': 200}, 'best_score': 0.9526210299105766}\n",
      "\n",
      "\n",
      "Executing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "208 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "208 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 149, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.92288752 0.98428737        nan 0.79187621        nan 0.97171927\n",
      " 0.98259468        nan        nan        nan 0.71887889        nan\n",
      " 0.95697026        nan 0.9388417         nan 0.97896986        nan\n",
      "        nan 0.98114424 0.71065979        nan 0.97993697        nan\n",
      "        nan        nan 0.9709916         nan        nan        nan\n",
      "        nan        nan        nan        nan 0.98380404 0.70727604\n",
      " 0.98138648        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.92459493 0.96857404        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.81099938 0.9637448         nan 0.98928571        nan 0.92072763\n",
      " 0.9597835         nan        nan        nan 0.97048611        nan\n",
      " 0.93401702        nan 0.92154679        nan 0.94418054        nan\n",
      "        nan 0.95954149 0.89285714        nan 0.94643571        nan\n",
      "        nan        nan 0.94729959        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.96296509 0.5\n",
      " 0.96107501        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.81272157 0.95497459        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.97034588 0.98351463        nan 0.29407949        nan 0.98928478\n",
      " 0.98186718        nan        nan        nan 0.04365881        nan\n",
      " 0.9184254         nan 0.86570968        nan 0.98681225        nan\n",
      "        nan 0.97692754 0.0164718         nan 0.98763462        nan\n",
      "        nan        nan 0.95467746        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.98269227 0.0041227\n",
      " 0.97610789        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.97775263 0.93737515        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.88225552 0.97347453        nan 0.45104025        nan 0.95362835\n",
      " 0.97066802        nan        nan        nan 0.08335201        nan\n",
      " 0.92597557        nan 0.89238174        nan 0.96496272        nan\n",
      "        nan 0.96812558 0.03231609        nan 0.96654085        nan\n",
      "        nan        nan 0.95075437        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97267206 0.00817529\n",
      " 0.96851232        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.8859171  0.94587036        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Stochastic Gradient Descent of dataset enron1_stemmed_tfidf is: \n",
      "SGDClassifier(alpha=0.001, loss='squared_hinge')\n",
      "SGDClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9797101449275363, 'weighted_precision': 0.9806952256166457, 'wighted_recall': 0.9797101449275363, 'weighted_f1': 0.9798865017932334, 'macro_precision': 0.9672807444678895, 'macro_recall': 0.9838199183993577, 'macro_f1': 0.9750833706863049, 'roc_auc': 0.9838199183993576}, 'confusion_matrix': array([[730,  19],\n",
      "       [  2, 284]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'alpha': 0.001}, 'best_score': 0.9842873695325128}\n",
      "\n",
      "\n",
      "Executing\n",
      "The best estimator for Perceptron of dataset enron1_stemmed_tfidf is: \n",
      "Perceptron(penalty='elasticnet', tol=1e-05)\n",
      "Perceptron classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9545893719806763, 'weighted_precision': 0.9551914552725165, 'wighted_recall': 0.9545893719806763, 'weighted_f1': 0.9548038511111524, 'macro_precision': 0.9397045350435181, 'macro_recall': 0.94809162799817, 'macro_f1': 0.9437700913988873, 'roc_auc': 0.94809162799817}, 'confusion_matrix': array([[721,  28],\n",
      "       [ 19, 267]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}, 'best_score': 0.9593906222259598}\n",
      "\n",
      "\n",
      "The best estimator for K-nearest Neighbors of dataset enron1_stemmed_tfidf is: \n",
      "KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'enron1_stemmed_tfidf', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.966183574879227, 'weighted_precision': 0.967004043268221, 'wighted_recall': 0.966183574879227, 'weighted_f1': 0.9664112949137104, 'macro_precision': 0.9523933946488294, 'macro_recall': 0.9647478689534764, 'macro_f1': 0.9583009583009583, 'roc_auc': 0.9647478689534764}, 'confusion_matrix': array([[725,  24],\n",
      "       [ 11, 275]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 7, 'weights': 'distance'}, 'best_score': 0.9644654220278641}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_stemmed_tfidf_X, enron1_y, \"enron1_stemmed_tfidf\")\n",
    "enron1_stemmed_tfidf_X = None\n",
    "enron1_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f456393",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron2_stemmed_tfidf_X, enron2_y, \"enron2_stemmed_tfidf\")\n",
    "enron2_stemmed_tfidf_X = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383048e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron3_stemmed_tfidf_X, enron3_y, \"enron3_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d23cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron4_stemmed_tfidf_X, enron4_y, \"enron4_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d8ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron5_stemmed_tfidf_X, enron5_y, \"enron5_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aacf781",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron6_stemmed_tfidf_X, enron6_y, \"enron6_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c3c074",
   "metadata": {},
   "source": [
    "## Lemmatizing + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_countvec = joblib.load(\"./preprocess/enron1_lemmatized_countvec.pkl\")\n",
    "enron2_lemmatized_countvec = joblib.load(\"./preprocess/enron2_lemmatized_countvec.pkl\")\n",
    "enron3_lemmatized_countvec = joblib.load(\"./preprocess/enron3_lemmatized_countvec.pkl\")\n",
    "enron4_lemmatized_countvec = joblib.load(\"./preprocess/enron4_lemmatized_countvec.pkl\")\n",
    "enron5_lemmatized_countvec = joblib.load(\"./preprocess/enron5_lemmatized_countvec.pkl\")\n",
    "enron6_lemmatized_countvec = joblib.load(\"./preprocess/enron6_lemmatized_countvec.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e5344",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_countvec_X, enron1_y = enron1_lemmatized_countvec[\"features\"], enron1_lemmatized_countvec[\"labels\"]\n",
    "enron2_lemmatized_countvec_X, enron2_y = enron2_lemmatized_countvec[\"features\"], enron2_lemmatized_countvec[\"labels\"]\n",
    "enron3_lemmatized_countvec_X, enron3_y = enron3_lemmatized_countvec[\"features\"], enron3_lemmatized_countvec[\"labels\"]\n",
    "enron4_lemmatized_countvec_X, enron4_y = enron4_lemmatized_countvec[\"features\"], enron4_lemmatized_countvec[\"labels\"]\n",
    "enron5_lemmatized_countvec_X, enron5_y = enron5_lemmatized_countvec[\"features\"], enron5_lemmatized_countvec[\"labels\"]\n",
    "enron6_lemmatized_countvec_X, enron6_y = enron6_lemmatized_countvec[\"features\"], enron6_lemmatized_countvec[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e127d9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1_lemmatized_countvec classification report\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_lemmatized_countvec_X, enron1_y, \"enron1_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron2_lemmatized_countvec_X, enron2_y, \"enron2_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017969ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron3_lemmatized_countvec_X, enron3_y, \"enron3_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c7b17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron4_lemmatized_countvec_X, enron4_y, \"enron4_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd4841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron5_lemmatized_countvec_X, enron5_y, \"enron5_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412fc5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron6_lemmatized_countvec_X, enron6_y, \"enron6_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba71a16e",
   "metadata": {},
   "source": [
    "## Lemmatizing + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebfa8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_tfidf = joblib.load(\"./preprocess/enron1_lemmatized_tfidf.pkl\")\n",
    "enron2_lemmatized_tfidf = joblib.load(\"./preprocess/enron2_lemmatized_tfidf.pkl\")\n",
    "enron3_lemmatized_tfidf = joblib.load(\"./preprocess/enron3_lemmatized_tfidf.pkl\")\n",
    "enron4_lemmatized_tfidf = joblib.load(\"./preprocess/enron4_lemmatized_tfidf.pkl\")\n",
    "enron5_lemmatized_tfidf = joblib.load(\"./preprocess/enron5_lemmatized_tfidf.pkl\")\n",
    "enron6_lemmatized_tfidf = joblib.load(\"./preprocess/enron6_lemmatized_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5c48eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_tfidf_X, enron1_y = enron1_lemmatized_tfidf[\"features\"], enron1_lemmatized_tfidf[\"labels\"]\n",
    "enron2_lemmatized_tfidf_X, enron2_y = enron2_lemmatized_tfidf[\"features\"], enron2_lemmatized_tfidf[\"labels\"]\n",
    "enron3_lemmatized_tfidf_X, enron3_y = enron3_lemmatized_tfidf[\"features\"], enron3_lemmatized_tfidf[\"labels\"]\n",
    "enron4_lemmatized_tfidf_X, enron4_y = enron4_lemmatized_tfidf[\"features\"], enron4_lemmatized_tfidf[\"labels\"]\n",
    "enron5_lemmatized_tfidf_X, enron5_y = enron5_lemmatized_tfidf[\"features\"], enron5_lemmatized_tfidf[\"labels\"]\n",
    "enron6_lemmatized_tfidf_X, enron6_y = enron6_lemmatized_tfidf[\"features\"], enron6_lemmatized_tfidf[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd94b2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1_lemmatized_tfidf classification report\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_lemmatized_tfidf_X, enron1_y, \"enron1_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a09033",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron2_lemmatized_tfidf_X, enron2_y, \"enron2_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1bcddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron3_lemmatized_tfidf_X, enron3_y, \"enron3_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc6e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron4_lemmatized_tfidf_X, enron4_y, \"enron4_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68e643",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron5_lemmatized_tfidf_X, enron5_y, \"enron5_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5926d485",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_evaluate_model(enron6_lemmatized_tfidf_X, enron6_y, \"enron6_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metric_results)\n",
    "\n",
    "def convert(dic):\n",
    "    dic[\"confusion_matrix\"] = dic[\"confusion_matrix\"].tolist()\n",
    "    return dic\n",
    "\n",
    "metric_results = list(map(convert, metric_results))\n",
    "\n",
    "add_to_json_array(\"./enron_classification_grid_report.json\", metric_results, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
