{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "292f758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "enron1_lemmatized_countvec = joblib.load(\"./preprocess/enron1_lemmatized_countvec.pkl\")\n",
    "enron2_lemmatized_countvec = joblib.load(\"./preprocess/enron2_lemmatized_countvec.pkl\")\n",
    "enron3_lemmatized_countvec = joblib.load(\"./preprocess/enron3_lemmatized_countvec.pkl\")\n",
    "enron4_lemmatized_countvec = joblib.load(\"./preprocess/enron4_lemmatized_countvec.pkl\")\n",
    "enron5_lemmatized_countvec = joblib.load(\"./preprocess/enron5_lemmatized_countvec.pkl\")\n",
    "enron6_lemmatized_countvec = joblib.load(\"./preprocess/enron6_lemmatized_countvec.pkl\")\n",
    "enron_lemmatized_countvec = joblib.load(\"./preprocess/enron_lemmatized_countvec.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8776d481",
   "metadata": {},
   "source": [
    "#### Evaluate different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17746896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "from traintest import ClassificationModel, models\n",
    "\n",
    "def train_and_evaluate_model(X, y, dataset_name):\n",
    "    print(f\"{dataset_name} classification report\")\n",
    "    print(\"=========================================\")\n",
    "    for model in models:\n",
    "        classification_model = ClassificationModel(model, dataset_name)\n",
    "        classification_model.train(X, y, save_model=True)\n",
    "        print(f\"{model.__class__.__name__} classification report\")\n",
    "        print(classification_model.evaluate())\n",
    "        classification_model.print_simple_confusion_matrix()\n",
    "        print(\"\\n\")\n",
    "\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b105974a",
   "metadata": {},
   "source": [
    "## Lemmatizing + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63e9e0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_countvec_X, enron1_y = enron1_lemmatized_countvec[\"features\"], enron1_lemmatized_countvec[\"labels\"]\n",
    "enron2_lemmatized_countvec_X, enron2_y = enron2_lemmatized_countvec[\"features\"], enron2_lemmatized_countvec[\"labels\"]\n",
    "enron3_lemmatized_countvec_X, enron3_y = enron3_lemmatized_countvec[\"features\"], enron3_lemmatized_countvec[\"labels\"]\n",
    "enron4_lemmatized_countvec_X, enron4_y = enron4_lemmatized_countvec[\"features\"], enron4_lemmatized_countvec[\"labels\"]\n",
    "enron5_lemmatized_countvec_X, enron5_y = enron5_lemmatized_countvec[\"features\"], enron5_lemmatized_countvec[\"labels\"]\n",
    "enron6_lemmatized_countvec_X, enron6_y = enron6_lemmatized_countvec[\"features\"], enron6_lemmatized_countvec[\"labels\"]\n",
    "enron_lemmatized_countvec_X, enron_y = enron_lemmatized_countvec[\"features\"], enron_lemmatized_countvec[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "87ebbc0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.96       749\n",
      "           1       0.85      0.96      0.90       286\n",
      "\n",
      "    accuracy                           0.94      1035\n",
      "   macro avg       0.92      0.95      0.93      1035\n",
      "weighted avg       0.95      0.94      0.94      1035\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[700  49]\n",
      " [ 11 275]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       749\n",
      "           1       0.90      0.99      0.94       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.95      0.97      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[718  31]\n",
      " [  3 283]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       749\n",
      "           1       0.87      0.74      0.80       286\n",
      "\n",
      "    accuracy                           0.90      1035\n",
      "   macro avg       0.89      0.85      0.87      1035\n",
      "weighted avg       0.90      0.90      0.90      1035\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[718  31]\n",
      " [ 73 213]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       749\n",
      "           1       0.95      0.97      0.96       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[735  14]\n",
      " [ 10 276]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       749\n",
      "           1       0.88      0.83      0.86       286\n",
      "\n",
      "    accuracy                           0.92      1035\n",
      "   macro avg       0.91      0.89      0.90      1035\n",
      "weighted avg       0.92      0.92      0.92      1035\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[717  32]\n",
      " [ 48 238]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       749\n",
      "           1       0.92      0.94      0.93       286\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.95      0.96      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[726  23]\n",
      " [ 16 270]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       749\n",
      "           1       0.94      0.97      0.96       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.97      0.97      1035\n",
      "weighted avg       0.98      0.97      0.98      1035\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[731  18]\n",
      " [  8 278]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91       749\n",
      "           1       0.73      0.88      0.80       286\n",
      "\n",
      "    accuracy                           0.88      1035\n",
      "   macro avg       0.84      0.88      0.86      1035\n",
      "weighted avg       0.89      0.88      0.88      1035\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[658  91]\n",
      " [ 35 251]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       749\n",
      "           1       0.94      0.98      0.96       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.98      0.97      1035\n",
      "weighted avg       0.98      0.97      0.98      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[730  19]\n",
      " [  7 279]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       749\n",
      "           1       0.90      0.96      0.93       286\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.94      0.96      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[718  31]\n",
      " [ 12 274]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       749\n",
      "           1       0.96      0.93      0.95       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.97      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[737  12]\n",
      " [ 19 267]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_lemmatized_countvec_X, enron1_y, \"enron1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "623fc312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron2 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       861\n",
      "           1       0.97      0.95      0.96       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.98      0.97      0.97      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[852   9]\n",
      " [ 17 294]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       861\n",
      "           1       0.97      0.99      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.98      0.99      0.98      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[851  10]\n",
      " [  4 307]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       861\n",
      "           1       0.93      0.99      0.96       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.96      0.98      0.97      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[836  25]\n",
      " [  2 309]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       861\n",
      "           1       0.98      0.95      0.96       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.98      0.97      0.98      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[855   6]\n",
      " [ 16 295]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       861\n",
      "           1       0.89      0.94      0.92       311\n",
      "\n",
      "    accuracy                           0.95      1172\n",
      "   macro avg       0.94      0.95      0.94      1172\n",
      "weighted avg       0.96      0.95      0.95      1172\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[826  35]\n",
      " [ 19 292]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       861\n",
      "           1       0.91      0.95      0.93       311\n",
      "\n",
      "    accuracy                           0.96      1172\n",
      "   macro avg       0.95      0.96      0.95      1172\n",
      "weighted avg       0.96      0.96      0.96      1172\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[833  28]\n",
      " [ 14 297]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       861\n",
      "           1       0.98      0.99      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.99      0.99      0.99      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[854   7]\n",
      " [  4 307]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93       861\n",
      "           1       0.76      0.92      0.83       311\n",
      "\n",
      "    accuracy                           0.90      1172\n",
      "   macro avg       0.87      0.91      0.88      1172\n",
      "weighted avg       0.91      0.90      0.91      1172\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[773  88]\n",
      " [ 26 285]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       861\n",
      "           1       0.97      0.98      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.98      0.99      0.98      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[851  10]\n",
      " [  5 306]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       861\n",
      "           1       0.90      0.95      0.93       311\n",
      "\n",
      "    accuracy                           0.96      1172\n",
      "   macro avg       0.94      0.96      0.95      1172\n",
      "weighted avg       0.96      0.96      0.96      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[830  31]\n",
      " [ 16 295]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       861\n",
      "           1       0.98      0.97      0.97       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.98      0.98      0.98      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[854   7]\n",
      " [  9 302]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron2_lemmatized_countvec_X, enron2_y, \"enron2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e3446f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron3 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89       796\n",
      "           1       0.99      0.36      0.53       307\n",
      "\n",
      "    accuracy                           0.82      1103\n",
      "   macro avg       0.90      0.68      0.71      1103\n",
      "weighted avg       0.86      0.82      0.79      1103\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[795   1]\n",
      " [195 112]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       796\n",
      "           1       0.98      0.97      0.98       307\n",
      "\n",
      "    accuracy                           0.99      1103\n",
      "   macro avg       0.99      0.98      0.99      1103\n",
      "weighted avg       0.99      0.99      0.99      1103\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[791   5]\n",
      " [  8 299]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.82       796\n",
      "           1       0.55      0.98      0.71       307\n",
      "\n",
      "    accuracy                           0.77      1103\n",
      "   macro avg       0.77      0.84      0.76      1103\n",
      "weighted avg       0.87      0.77      0.79      1103\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[552 244]\n",
      " [  5 302]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       796\n",
      "           1       0.98      0.93      0.95       307\n",
      "\n",
      "    accuracy                           0.97      1103\n",
      "   macro avg       0.97      0.96      0.97      1103\n",
      "weighted avg       0.97      0.97      0.97      1103\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[789   7]\n",
      " [ 23 284]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       796\n",
      "           1       0.92      0.90      0.91       307\n",
      "\n",
      "    accuracy                           0.95      1103\n",
      "   macro avg       0.94      0.94      0.94      1103\n",
      "weighted avg       0.95      0.95      0.95      1103\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[772  24]\n",
      " [ 30 277]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       796\n",
      "           1       0.89      0.97      0.93       307\n",
      "\n",
      "    accuracy                           0.96      1103\n",
      "   macro avg       0.94      0.96      0.95      1103\n",
      "weighted avg       0.96      0.96      0.96      1103\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[761  35]\n",
      " [ 10 297]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       796\n",
      "           1       0.98      0.97      0.98       307\n",
      "\n",
      "    accuracy                           0.99      1103\n",
      "   macro avg       0.99      0.98      0.98      1103\n",
      "weighted avg       0.99      0.99      0.99      1103\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[791   5]\n",
      " [  9 298]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.90       796\n",
      "           1       0.69      0.87      0.77       307\n",
      "\n",
      "    accuracy                           0.86      1103\n",
      "   macro avg       0.82      0.86      0.83      1103\n",
      "weighted avg       0.87      0.86      0.86      1103\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[679 117]\n",
      " [ 41 266]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       796\n",
      "           1       0.97      0.96      0.97       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.98      0.98      0.98      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[786  10]\n",
      " [ 11 296]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       796\n",
      "           1       0.98      0.86      0.91       307\n",
      "\n",
      "    accuracy                           0.95      1103\n",
      "   macro avg       0.96      0.92      0.94      1103\n",
      "weighted avg       0.96      0.95      0.95      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[790   6]\n",
      " [ 44 263]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       796\n",
      "           1       0.97      0.95      0.96       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.98      0.97      0.97      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[787   9]\n",
      " [ 16 291]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron3_lemmatized_countvec_X, enron3_y, \"enron3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4c70686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron4 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94       322\n",
      "           1       0.96      1.00      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.98      0.94      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[285  37]\n",
      " [  0 878]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       322\n",
      "           1       0.99      0.99      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[314   8]\n",
      " [ 12 866]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79       322\n",
      "           1       0.99      0.82      0.89       878\n",
      "\n",
      "    accuracy                           0.86      1200\n",
      "   macro avg       0.82      0.89      0.84      1200\n",
      "weighted avg       0.90      0.86      0.87      1200\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[312  10]\n",
      " [160 718]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       322\n",
      "           1       0.98      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.99      0.97      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[304  18]\n",
      " [  1 877]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       322\n",
      "           1       0.98      0.99      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.96      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  20]\n",
      " [ 13 865]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       322\n",
      "           1       0.98      0.99      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.97      0.97      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  20]\n",
      " [  6 872]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98       322\n",
      "           1       0.99      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.98      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[310  12]\n",
      " [  1 877]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.87       322\n",
      "           1       0.92      1.00      0.96       878\n",
      "\n",
      "    accuracy                           0.94      1200\n",
      "   macro avg       0.96      0.89      0.92      1200\n",
      "weighted avg       0.94      0.94      0.94      1200\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[250  72]\n",
      " [  1 877]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       322\n",
      "           1       0.99      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.98      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[312  10]\n",
      " [  2 876]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       322\n",
      "           1       0.97      1.00      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.98      0.95      0.97      1200\n",
      "weighted avg       0.98      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[293  29]\n",
      " [  1 877]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       322\n",
      "           1       0.99      0.98      0.98       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.97      0.98      0.97      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[316   6]\n",
      " [ 21 857]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron4_lemmatized_countvec_X, enron4_y, \"enron4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f036894b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron5 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.88      0.93       313\n",
      "           1       0.95      1.00      0.97       722\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.97      0.94      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[276  37]\n",
      " [  2 720]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       313\n",
      "           1       1.00      1.00      1.00       722\n",
      "\n",
      "    accuracy                           1.00      1035\n",
      "   macro avg       1.00      1.00      1.00      1035\n",
      "weighted avg       1.00      1.00      1.00      1035\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[311   2]\n",
      " [  2 720]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       313\n",
      "           1       0.97      1.00      0.98       722\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.98      0.96      0.97      1035\n",
      "weighted avg       0.98      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[287  26]\n",
      " [  0 722]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       313\n",
      "           1       0.99      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.98      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[304   9]\n",
      " [  1 721]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       313\n",
      "           1       0.97      0.97      0.97       722\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[290  23]\n",
      " [ 20 702]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       313\n",
      "           1       0.97      1.00      0.98       722\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[294  19]\n",
      " [  3 719]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       313\n",
      "           1       0.99      0.99      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.98      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[305   8]\n",
      " [  4 718]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.76      0.85       313\n",
      "           1       0.90      0.99      0.94       722\n",
      "\n",
      "    accuracy                           0.92      1035\n",
      "   macro avg       0.93      0.87      0.89      1035\n",
      "weighted avg       0.92      0.92      0.91      1035\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[237  76]\n",
      " [ 10 712]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97       313\n",
      "           1       0.98      0.99      0.99       722\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  11]\n",
      " [  8 714]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95       313\n",
      "           1       0.96      1.00      0.98       722\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.98      0.95      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[283  30]\n",
      " [  0 722]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       313\n",
      "           1       0.99      0.99      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[304   9]\n",
      " [  6 716]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron5_lemmatized_countvec_X, enron5_y, \"enron5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "283c7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron6 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90       330\n",
      "           1       0.94      1.00      0.97       870\n",
      "\n",
      "    accuracy                           0.95      1200\n",
      "   macro avg       0.97      0.91      0.94      1200\n",
      "weighted avg       0.95      0.95      0.95      1200\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[272  58]\n",
      " [  0 870]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       330\n",
      "           1       0.99      0.98      0.99       870\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[325   5]\n",
      " [ 15 855]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       330\n",
      "           1       0.98      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.96      0.97      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[311  19]\n",
      " [ 12 858]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.96       330\n",
      "           1       0.98      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.97      0.97      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[311  19]\n",
      " [  8 862]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90       330\n",
      "           1       0.97      0.96      0.96       870\n",
      "\n",
      "    accuracy                           0.95      1200\n",
      "   macro avg       0.93      0.94      0.93      1200\n",
      "weighted avg       0.95      0.95      0.95      1200\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[301  29]\n",
      " [ 36 834]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94       330\n",
      "           1       0.96      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.95      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[297  33]\n",
      " [  6 864]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       330\n",
      "           1       0.98      1.00      0.99       870\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.97      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[310  20]\n",
      " [  3 867]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.69      0.79       330\n",
      "           1       0.89      0.98      0.94       870\n",
      "\n",
      "    accuracy                           0.90      1200\n",
      "   macro avg       0.91      0.84      0.86      1200\n",
      "weighted avg       0.90      0.90      0.90      1200\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[228 102]\n",
      " [ 16 854]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95       330\n",
      "           1       0.97      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.98      0.96      0.97      1200\n",
      "weighted avg       0.98      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[306  24]\n",
      " [  6 864]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       330\n",
      "           1       0.95      1.00      0.97       870\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.97      0.92      0.94      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[282  48]\n",
      " [  4 866]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       330\n",
      "           1       0.98      0.98      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.97      0.97      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[315  15]\n",
      " [ 17 853]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron6_lemmatized_countvec_X, enron6_y, \"enron6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd5806fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_enron classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3282\n",
      "           1       0.94      0.99      0.96      3461\n",
      "\n",
      "    accuracy                           0.96      6743\n",
      "   macro avg       0.96      0.96      0.96      6743\n",
      "weighted avg       0.96      0.96      0.96      6743\n",
      "\n",
      "Confusion Matrix for SVM on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3061  221]\n",
      " [  35 3426]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3282\n",
      "           1       0.98      0.99      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3220   62]\n",
      " [  35 3426]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3282\n",
      "           1       0.98      0.99      0.99      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3206   76]\n",
      " [  27 3434]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      3282\n",
      "           1       0.98      0.99      0.98      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3222   60]\n",
      " [  51 3410]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95      3282\n",
      "           1       0.95      0.95      0.95      3461\n",
      "\n",
      "    accuracy                           0.95      6743\n",
      "   macro avg       0.95      0.95      0.95      6743\n",
      "weighted avg       0.95      0.95      0.95      6743\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3109  173]\n",
      " [ 164 3297]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.94      3282\n",
      "           1       0.93      0.97      0.95      3461\n",
      "\n",
      "    accuracy                           0.95      6743\n",
      "   macro avg       0.95      0.95      0.95      6743\n",
      "weighted avg       0.95      0.95      0.95      6743\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3042  240]\n",
      " [ 119 3342]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3282\n",
      "           1       0.98      0.99      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3214   68]\n",
      " [  20 3441]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.80      0.87      3282\n",
      "           1       0.84      0.95      0.89      3461\n",
      "\n",
      "    accuracy                           0.88      6743\n",
      "   macro avg       0.89      0.88      0.88      6743\n",
      "weighted avg       0.89      0.88      0.88      6743\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[2640  642]\n",
      " [ 177 3284]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3282\n",
      "           1       0.97      0.99      0.98      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3183   99]\n",
      " [  35 3426]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3282\n",
      "           1       0.91      0.98      0.95      3461\n",
      "\n",
      "    accuracy                           0.94      6743\n",
      "   macro avg       0.95      0.94      0.94      6743\n",
      "weighted avg       0.95      0.94      0.94      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[2948  334]\n",
      " [  53 3408]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3282\n",
      "           1       0.99      0.98      0.99      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3239   43]\n",
      " [  59 3402]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron_lemmatized_countvec_X, enron_y, \"merged_enron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad59bbf3",
   "metadata": {},
   "source": [
    "## Lemmatizing + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a18a421f",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_tfidf = joblib.load(\"./preprocess/enron1_lemmatized_tfidf.pkl\")\n",
    "enron2_lemmatized_tfidf = joblib.load(\"./preprocess/enron2_lemmatized_tfidf.pkl\")\n",
    "enron3_lemmatized_tfidf = joblib.load(\"./preprocess/enron3_lemmatized_tfidf.pkl\")\n",
    "enron4_lemmatized_tfidf = joblib.load(\"./preprocess/enron4_lemmatized_tfidf.pkl\")\n",
    "enron5_lemmatized_tfidf = joblib.load(\"./preprocess/enron5_lemmatized_tfidf.pkl\")\n",
    "enron6_lemmatized_tfidf = joblib.load(\"./preprocess/enron6_lemmatized_tfidf.pkl\")\n",
    "enron_lemmatized_tfidf = joblib.load(\"./preprocess/enron_lemmatized_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a425b5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_lemmatized_tfidf_X, enron1_y = enron1_lemmatized_tfidf[\"features\"], enron1_lemmatized_tfidf[\"labels\"]\n",
    "enron2_lemmatized_tfidf_X, enron2_y = enron2_lemmatized_tfidf[\"features\"], enron2_lemmatized_tfidf[\"labels\"]\n",
    "enron3_lemmatized_tfidf_X, enron3_y = enron3_lemmatized_tfidf[\"features\"], enron3_lemmatized_tfidf[\"labels\"]\n",
    "enron4_lemmatized_tfidf_X, enron4_y = enron4_lemmatized_tfidf[\"features\"], enron4_lemmatized_tfidf[\"labels\"]\n",
    "enron5_lemmatized_tfidf_X, enron5_y = enron5_lemmatized_tfidf[\"features\"], enron5_lemmatized_tfidf[\"labels\"]\n",
    "enron6_lemmatized_tfidf_X, enron6_y = enron6_lemmatized_tfidf[\"features\"], enron6_lemmatized_tfidf[\"labels\"]\n",
    "enron_lemmatized_tfidf_X, enron_y = enron_lemmatized_tfidf[\"features\"], enron_lemmatized_tfidf[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "359c3eaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron1 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       749\n",
      "           1       0.95      0.99      0.97       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.99      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[735  14]\n",
      " [  3 283]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       749\n",
      "           1       0.94      0.96      0.95       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.97      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[732  17]\n",
      " [ 11 275]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93       749\n",
      "           1       0.87      0.74      0.80       286\n",
      "\n",
      "    accuracy                           0.90      1035\n",
      "   macro avg       0.89      0.85      0.87      1035\n",
      "weighted avg       0.90      0.90      0.90      1035\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[718  31]\n",
      " [ 73 213]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       749\n",
      "           1       0.94      0.98      0.96       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.98      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[732  17]\n",
      " [  7 279]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       749\n",
      "           1       0.87      0.87      0.87       286\n",
      "\n",
      "    accuracy                           0.93      1035\n",
      "   macro avg       0.91      0.91      0.91      1035\n",
      "weighted avg       0.93      0.93      0.93      1035\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[713  36]\n",
      " [ 37 249]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       749\n",
      "           1       0.89      0.94      0.91       286\n",
      "\n",
      "    accuracy                           0.95      1035\n",
      "   macro avg       0.93      0.95      0.94      1035\n",
      "weighted avg       0.95      0.95      0.95      1035\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[716  33]\n",
      " [ 18 268]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       749\n",
      "           1       0.95      0.99      0.97       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[733  16]\n",
      " [  4 282]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       749\n",
      "           1       0.93      0.97      0.95       286\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.97      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[728  21]\n",
      " [ 10 276]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       749\n",
      "           1       0.95      0.98      0.96       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.98      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[733  16]\n",
      " [  5 281]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       749\n",
      "           1       0.90      0.95      0.93       286\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.94      0.96      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[719  30]\n",
      " [ 13 273]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       749\n",
      "           1       0.96      0.96      0.96       286\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.97      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron1:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[739  10]\n",
      " [ 12 274]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron1_lemmatized_tfidf_X, enron1_y, \"enron1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c1482ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron2 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       861\n",
      "           1       0.99      0.98      0.99       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.99      0.99      0.99      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[859   2]\n",
      " [  7 304]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       861\n",
      "           1       1.00      0.94      0.97       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.99      0.97      0.98      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[861   0]\n",
      " [ 20 291]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       861\n",
      "           1       0.93      0.99      0.96       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.96      0.98      0.97      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[836  25]\n",
      " [  2 309]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       861\n",
      "           1       0.98      0.95      0.97       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.98      0.97      0.98      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[856   5]\n",
      " [ 14 297]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       861\n",
      "           1       0.91      0.95      0.93       311\n",
      "\n",
      "    accuracy                           0.96      1172\n",
      "   macro avg       0.95      0.96      0.95      1172\n",
      "weighted avg       0.96      0.96      0.96      1172\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[832  29]\n",
      " [ 17 294]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       861\n",
      "           1       0.92      0.98      0.95       311\n",
      "\n",
      "    accuracy                           0.97      1172\n",
      "   macro avg       0.95      0.97      0.96      1172\n",
      "weighted avg       0.97      0.97      0.97      1172\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[833  28]\n",
      " [  7 304]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       861\n",
      "           1       0.99      0.97      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.99      0.98      0.99      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[859   2]\n",
      " [  9 302]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       861\n",
      "           1       0.95      0.97      0.96       311\n",
      "\n",
      "    accuracy                           0.98      1172\n",
      "   macro avg       0.97      0.98      0.98      1172\n",
      "weighted avg       0.98      0.98      0.98      1172\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[846  15]\n",
      " [  8 303]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       861\n",
      "           1       0.99      0.98      0.99       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.99      0.99      0.99      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[858   3]\n",
      " [  6 305]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       861\n",
      "           1       0.97      0.91      0.94       311\n",
      "\n",
      "    accuracy                           0.97      1172\n",
      "   macro avg       0.97      0.95      0.96      1172\n",
      "weighted avg       0.97      0.97      0.97      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[852   9]\n",
      " [ 27 284]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       861\n",
      "           1       0.98      0.98      0.98       311\n",
      "\n",
      "    accuracy                           0.99      1172\n",
      "   macro avg       0.99      0.99      0.99      1172\n",
      "weighted avg       0.99      0.99      0.99      1172\n",
      "\n",
      "Confusion Matrix for  on dataset enron2:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[854   7]\n",
      " [  6 305]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron2_lemmatized_tfidf_X, enron2_y, \"enron2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1f8d729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron3 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       796\n",
      "           1       1.00      0.98      0.99       307\n",
      "\n",
      "    accuracy                           0.99      1103\n",
      "   macro avg       1.00      0.99      0.99      1103\n",
      "weighted avg       0.99      0.99      0.99      1103\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[796   0]\n",
      " [  7 300]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       796\n",
      "           1       1.00      0.88      0.94       307\n",
      "\n",
      "    accuracy                           0.97      1103\n",
      "   macro avg       0.98      0.94      0.96      1103\n",
      "weighted avg       0.97      0.97      0.97      1103\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[796   0]\n",
      " [ 37 270]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.82       796\n",
      "           1       0.55      0.98      0.71       307\n",
      "\n",
      "    accuracy                           0.77      1103\n",
      "   macro avg       0.77      0.84      0.76      1103\n",
      "weighted avg       0.87      0.77      0.79      1103\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[552 244]\n",
      " [  5 302]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       796\n",
      "           1       0.97      0.94      0.96       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.97      0.97      0.97      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[787   9]\n",
      " [ 18 289]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       796\n",
      "           1       0.93      0.93      0.93       307\n",
      "\n",
      "    accuracy                           0.96      1103\n",
      "   macro avg       0.95      0.95      0.95      1103\n",
      "weighted avg       0.96      0.96      0.96      1103\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[775  21]\n",
      " [ 23 284]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       796\n",
      "           1       0.91      0.96      0.93       307\n",
      "\n",
      "    accuracy                           0.96      1103\n",
      "   macro avg       0.95      0.96      0.95      1103\n",
      "weighted avg       0.96      0.96      0.96      1103\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[767  29]\n",
      " [ 13 294]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       796\n",
      "           1       1.00      0.93      0.96       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.99      0.97      0.98      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[796   0]\n",
      " [ 21 286]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       796\n",
      "           1       0.97      0.95      0.96       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.98      0.97      0.97      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[787   9]\n",
      " [ 16 291]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       796\n",
      "           1       0.99      0.98      0.98       307\n",
      "\n",
      "    accuracy                           0.99      1103\n",
      "   macro avg       0.99      0.99      0.99      1103\n",
      "weighted avg       0.99      0.99      0.99      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[793   3]\n",
      " [  7 300]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       796\n",
      "           1       0.98      0.85      0.91       307\n",
      "\n",
      "    accuracy                           0.95      1103\n",
      "   macro avg       0.96      0.92      0.94      1103\n",
      "weighted avg       0.96      0.95      0.95      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[791   5]\n",
      " [ 45 262]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       796\n",
      "           1       0.96      0.96      0.96       307\n",
      "\n",
      "    accuracy                           0.98      1103\n",
      "   macro avg       0.97      0.97      0.97      1103\n",
      "weighted avg       0.98      0.98      0.98      1103\n",
      "\n",
      "Confusion Matrix for  on dataset enron3:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[784  12]\n",
      " [ 11 296]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron3_lemmatized_tfidf_X, enron3_y, \"enron3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "346e332c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron4 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       322\n",
      "           1       0.98      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.99      0.97      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[303  19]\n",
      " [  0 878]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.85      0.87       322\n",
      "           1       0.95      0.96      0.95       878\n",
      "\n",
      "    accuracy                           0.93      1200\n",
      "   macro avg       0.92      0.91      0.91      1200\n",
      "weighted avg       0.93      0.93      0.93      1200\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[274  48]\n",
      " [ 35 843]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79       322\n",
      "           1       0.99      0.82      0.89       878\n",
      "\n",
      "    accuracy                           0.86      1200\n",
      "   macro avg       0.82      0.89      0.84      1200\n",
      "weighted avg       0.90      0.86      0.87      1200\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[312  10]\n",
      " [160 718]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97       322\n",
      "           1       0.98      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.99      0.97      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  20]\n",
      " [  0 878]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93       322\n",
      "           1       0.97      0.98      0.98       878\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.96      0.95      0.95      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[298  24]\n",
      " [ 19 859]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.95       322\n",
      "           1       0.97      0.99      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.96      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[296  26]\n",
      " [  8 870]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       322\n",
      "           1       0.96      1.00      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.98      0.94      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[284  38]\n",
      " [  0 878]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       322\n",
      "           1       0.99      0.99      0.99       878\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.98      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[312  10]\n",
      " [ 10 868]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       322\n",
      "           1       0.99      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.99      0.99      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[314   8]\n",
      " [  1 877]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.89      0.94       322\n",
      "           1       0.96      1.00      0.98       878\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.98      0.94      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[287  35]\n",
      " [  2 876]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       322\n",
      "           1       0.99      1.00      0.99       878\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.98      0.98      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron4:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[309  13]\n",
      " [  4 874]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron4_lemmatized_tfidf_X, enron4_y, \"enron4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9e629738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron5 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       313\n",
      "           1       0.98      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.98      0.98      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[301  12]\n",
      " [  2 720]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98       313\n",
      "           1       0.99      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.98      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[304   9]\n",
      " [  1 721]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       313\n",
      "           1       0.97      1.00      0.98       722\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.98      0.96      0.97      1035\n",
      "weighted avg       0.98      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[287  26]\n",
      " [  0 722]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99       313\n",
      "           1       0.99      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.99      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[305   8]\n",
      " [  1 721]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       313\n",
      "           1       0.98      0.98      0.98       722\n",
      "\n",
      "    accuracy                           0.97      1035\n",
      "   macro avg       0.96      0.96      0.96      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[296  17]\n",
      " [ 16 706]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96       313\n",
      "           1       0.97      0.99      0.98       722\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.97      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[294  19]\n",
      " [  6 716]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96       313\n",
      "           1       0.97      1.00      0.98       722\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.96      0.97      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[291  22]\n",
      " [  1 721]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       313\n",
      "           1       0.98      0.99      0.99       722\n",
      "\n",
      "    accuracy                           0.98      1035\n",
      "   macro avg       0.98      0.98      0.98      1035\n",
      "weighted avg       0.98      0.98      0.98      1035\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  11]\n",
      " [  7 715]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       313\n",
      "           1       0.99      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.99      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[307   6]\n",
      " [  3 719]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94       313\n",
      "           1       0.95      1.00      0.97       722\n",
      "\n",
      "    accuracy                           0.96      1035\n",
      "   macro avg       0.97      0.94      0.96      1035\n",
      "weighted avg       0.97      0.96      0.96      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[277  36]\n",
      " [  1 721]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       313\n",
      "           1       0.99      1.00      0.99       722\n",
      "\n",
      "    accuracy                           0.99      1035\n",
      "   macro avg       0.99      0.99      0.99      1035\n",
      "weighted avg       0.99      0.99      0.99      1035\n",
      "\n",
      "Confusion Matrix for  on dataset enron5:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[305   8]\n",
      " [  3 719]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron5_lemmatized_tfidf_X, enron5_y, \"enron5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "137c105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enron6 classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96       330\n",
      "           1       0.97      1.00      0.98       870\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.96      0.97      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for SVM on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[304  26]\n",
      " [  1 869]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94       330\n",
      "           1       0.97      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.95      0.96      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[301  29]\n",
      " [  9 861]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95       330\n",
      "           1       0.98      0.99      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.96      0.97      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[311  19]\n",
      " [ 12 858]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.96       330\n",
      "           1       0.98      1.00      0.99       870\n",
      "\n",
      "    accuracy                           0.98      1200\n",
      "   macro avg       0.98      0.97      0.98      1200\n",
      "weighted avg       0.98      0.98      0.98      1200\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[309  21]\n",
      " [  2 868]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92       330\n",
      "           1       0.97      0.97      0.97       870\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.95      0.94      0.94      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[302  28]\n",
      " [ 25 845]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.93       330\n",
      "           1       0.96      0.99      0.97       870\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.96      0.94      0.95      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[292  38]\n",
      " [  9 861]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.93       330\n",
      "           1       0.95      1.00      0.97       870\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.97      0.93      0.95      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[285  45]\n",
      " [  1 869]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.92       330\n",
      "           1       0.95      1.00      0.97       870\n",
      "\n",
      "    accuracy                           0.96      1200\n",
      "   macro avg       0.97      0.93      0.95      1200\n",
      "weighted avg       0.96      0.96      0.96      1200\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[287  43]\n",
      " [  4 866]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       330\n",
      "           1       0.98      1.00      0.99       870\n",
      "\n",
      "    accuracy                           0.99      1200\n",
      "   macro avg       0.99      0.98      0.98      1200\n",
      "weighted avg       0.99      0.99      0.99      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[315  15]\n",
      " [  2 868]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.89       330\n",
      "           1       0.94      1.00      0.96       870\n",
      "\n",
      "    accuracy                           0.95      1200\n",
      "   macro avg       0.96      0.91      0.93      1200\n",
      "weighted avg       0.95      0.95      0.95      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[270  60]\n",
      " [  4 866]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95       330\n",
      "           1       0.98      0.98      0.98       870\n",
      "\n",
      "    accuracy                           0.97      1200\n",
      "   macro avg       0.97      0.97      0.97      1200\n",
      "weighted avg       0.97      0.97      0.97      1200\n",
      "\n",
      "Confusion Matrix for  on dataset enron6:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[314  16]\n",
      " [ 14 856]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron6_lemmatized_tfidf_X, enron6_y, \"enron6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "383adfa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_enron classification report\n",
      "=========================================\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SVC classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3282\n",
      "           1       0.98      1.00      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for SVM on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3221   61]\n",
      " [  14 3447]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "MultinomialNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3282\n",
      "           1       0.99      0.99      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for Multinomial Naive Bayes on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3233   49]\n",
      " [  34 3427]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "BernoulliNB classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      3282\n",
      "           1       0.98      0.99      0.98      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for Bernoulli Naive Bayes on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3195   87]\n",
      " [  23 3438]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "RandomForestClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      3282\n",
      "           1       0.98      0.99      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for Random Forest on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3219   63]\n",
      " [  25 3436]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "DecisionTreeClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.95      3282\n",
      "           1       0.95      0.96      0.96      3461\n",
      "\n",
      "    accuracy                           0.95      6743\n",
      "   macro avg       0.95      0.95      0.95      6743\n",
      "weighted avg       0.95      0.95      0.95      6743\n",
      "\n",
      "Confusion Matrix for Decision Tree on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3110  172]\n",
      " [ 134 3327]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "AdaBoostClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95      3282\n",
      "           1       0.93      0.97      0.95      3461\n",
      "\n",
      "    accuracy                           0.95      6743\n",
      "   macro avg       0.95      0.95      0.95      6743\n",
      "weighted avg       0.95      0.95      0.95      6743\n",
      "\n",
      "Confusion Matrix for AdaBoost on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3038  244]\n",
      " [ 107 3354]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "LogisticRegression classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98      3282\n",
      "           1       0.97      1.00      0.98      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for Logistic Regression on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3189   93]\n",
      " [  14 3447]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "KNeighborsClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54      3282\n",
      "           1       0.63      1.00      0.77      3461\n",
      "\n",
      "    accuracy                           0.69      6743\n",
      "   macro avg       0.81      0.69      0.66      6743\n",
      "weighted avg       0.81      0.69      0.66      6743\n",
      "\n",
      "Confusion Matrix for K-nearest Neighbors on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[1224 2058]\n",
      " [   2 3459]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "SGDClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3282\n",
      "           1       0.98      1.00      0.99      3461\n",
      "\n",
      "    accuracy                           0.99      6743\n",
      "   macro avg       0.99      0.99      0.99      6743\n",
      "weighted avg       0.99      0.99      0.99      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3207   75]\n",
      " [  13 3448]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "GradientBoostingClassifier classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      3282\n",
      "           1       0.91      0.98      0.94      3461\n",
      "\n",
      "    accuracy                           0.94      6743\n",
      "   macro avg       0.94      0.94      0.94      6743\n",
      "weighted avg       0.94      0.94      0.94      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[2950  332]\n",
      " [  67 3394]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "The model has already been trained. This process will overwrite the previous training.\n",
      "Perceptron classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      3282\n",
      "           1       0.98      0.99      0.98      3461\n",
      "\n",
      "    accuracy                           0.98      6743\n",
      "   macro avg       0.98      0.98      0.98      6743\n",
      "weighted avg       0.98      0.98      0.98      6743\n",
      "\n",
      "Confusion Matrix for  on dataset merged_enron:\n",
      "Pattern:\n",
      "True Negative (TN) | False Positive (FP)\n",
      "False Negative (FN) | True Positive (TP)\n",
      "[[3220   62]\n",
      " [  46 3415]]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(enron_lemmatized_tfidf_X, enron_y, \"merged_enron\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
