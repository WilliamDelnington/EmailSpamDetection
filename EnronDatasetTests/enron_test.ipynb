{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12bf2968-6301-4fb3-88a6-6eb49ff1395b",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e101ce-cdcd-4aa6-bd78-b996deb24b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2c66cc-de82-4cf0-a2d4-3877e654ab6c",
   "metadata": {},
   "source": [
    "Specify Enron email text files paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d71323c0-cbc5-4cf8-a66c-6208ca42cd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"./Enron Dataset Tests/enron1\",\n",
    "    \"./Enron Dataset Tests/enron2\",\n",
    "    \"./Enron Dataset Tests/enron3\",\n",
    "    \"./Enron Dataset Tests/enron4\",\n",
    "    \"./Enron Dataset Tests/enron5\",\n",
    "    \"./Enron Dataset Tests/enron6\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a27b18-4fe7-4a81-a241-d5046428f981",
   "metadata": {},
   "source": [
    "Specify function to load emails:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3836f-e79a-44ab-bcf4-6f9d35e0c9f8",
   "metadata": {},
   "source": [
    "After loading the datasets, pre-process them by removing additional white spaces, punctuations, digits, and next lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25962d54-7f7c-4c9e-bde3-c4d02e45bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to E:/nltk...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\", download_dir=\"E:/nltk\")\n",
    "\n",
    "def preprocess_email(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\n', ' ', text)\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in text.split() if word not in stop_words]\n",
    "\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25232bef-5d4a-462c-9c7f-ffd1fa358ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji\n",
    "\n",
    "def handle_emoji(text):\n",
    "    emoji_corpus = [emoji.demojize(doc) for doc in text]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47bc28da-aafb-4a03-8987-00d041761859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to E:/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47416981-0550-48a1-86be-24d2bcdd2eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"./enron1\"\n",
    "\n",
    "texts, labels = preprocessing.load_emails(folder_path)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f6b8a6-9740-436e-b096-9e402e116876",
   "metadata": {},
   "source": [
    "Store the enron1 (or any enron folder) data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427990a2-f772-4945-a4a5-edd729a60fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"label\": labels,\n",
    "    \"text\": texts\n",
    "})\n",
    "\n",
    "match folder_path:\n",
    "    case \"./enron1\":\n",
    "        df.to_csv(\"./enron1.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case \"./enron2\":\n",
    "        df.to_csv(\"./enron2.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case \"./enron3\":\n",
    "        df.to_csv(\"./enron3.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case \"./enron4\":\n",
    "        df.to_csv(\"./enron4.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case \"./enron5\":\n",
    "        df.to_csv(\"./enron5.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case \"./enron6\":\n",
    "        df.to_csv(\"./enron6.csv\", index=False, escapechar=\"\\\\\")\n",
    "    case _:\n",
    "        raise ValueError(\"No path exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411f9265-2051-4243-8aea-c9db9ca63851",
   "metadata": {},
   "source": [
    "Extract the urls provided in each email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3efc211d-2c31-483b-81ce-7c2c2fe44725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1030\n"
     ]
    }
   ],
   "source": [
    "email_urls = []\n",
    "\n",
    "for text in texts:\n",
    "    urls = preprocessing.extract_urls(text)\n",
    "    email_urls.extend(urls)\n",
    "\n",
    "print(len(email_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31482d29-328f-4bf9-adf4-3cec87f4fa9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['subject',\n",
       " 'meter',\n",
       " '7268',\n",
       " 'nov',\n",
       " 'allocation',\n",
       " 'fyi',\n",
       " 'forwarded',\n",
       " 'lauri',\n",
       " 'allen',\n",
       " 'hou',\n",
       " 'ect',\n",
       " '12',\n",
       " '14',\n",
       " '99',\n",
       " '12',\n",
       " '17',\n",
       " 'pm',\n",
       " 'kimberly',\n",
       " 'vaughn',\n",
       " '12',\n",
       " '10',\n",
       " '99',\n",
       " '02',\n",
       " '54',\n",
       " 'pm',\n",
       " 'lauri',\n",
       " 'allen',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'cc',\n",
       " 'mary',\n",
       " 'smith',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'subject',\n",
       " 'meter',\n",
       " '7268',\n",
       " 'nov',\n",
       " 'allocation',\n",
       " 'lauri',\n",
       " 'put',\n",
       " 'strangas',\n",
       " 'gas',\n",
       " 'get',\n",
       " 'contract',\n",
       " 'daren',\n",
       " 'forwarded',\n",
       " 'kimberly',\n",
       " 'vaughn',\n",
       " 'hou',\n",
       " 'ect',\n",
       " '12',\n",
       " '10',\n",
       " '99',\n",
       " '01',\n",
       " '52',\n",
       " 'pm',\n",
       " 'lauri',\n",
       " 'allen',\n",
       " '12',\n",
       " '09',\n",
       " '99',\n",
       " '01',\n",
       " '20',\n",
       " 'pm',\n",
       " 'kimberly',\n",
       " 'vaughn',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'anita',\n",
       " 'luong',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'cc',\n",
       " 'howard',\n",
       " 'b',\n",
       " 'camp',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'mary',\n",
       " 'smith',\n",
       " 'hou',\n",
       " 'ect',\n",
       " 'ect',\n",
       " 'subject',\n",
       " 'meter',\n",
       " '7268',\n",
       " 'nov',\n",
       " 'allocation',\n",
       " 'kim',\n",
       " 'anita',\n",
       " 'volume',\n",
       " '7247',\n",
       " 'mm',\n",
       " 'shows',\n",
       " 'allocated',\n",
       " 'reliant',\n",
       " '201',\n",
       " 'contract',\n",
       " 'november',\n",
       " 'nomination',\n",
       " 'reliant',\n",
       " 'point',\n",
       " 'november',\n",
       " 'therefore',\n",
       " 'volume',\n",
       " 'allocated',\n",
       " 'contract',\n",
       " 'please',\n",
       " 'make',\n",
       " 'sure',\n",
       " 'volumes',\n",
       " 'moved',\n",
       " 'reliant',\n",
       " 'contract',\n",
       " 'prior',\n",
       " 'november',\n",
       " 'close',\n",
       " 'thanks']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text = preprocessing.preprocess_text(texts[4])\n",
    "\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b388b7-0083-4489-bad1-9905fe9fb00c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
