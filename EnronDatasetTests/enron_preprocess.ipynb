{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d8e9181",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea073bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "enron1_preprocessed = pd.read_csv(\"./csv/preprocessed_enron1_data.csv\")\n",
    "enron2_preprocessed = pd.read_csv(\"./csv/preprocessed_enron2_data.csv\")\n",
    "enron3_preprocessed = pd.read_csv(\"./csv/preprocessed_enron3_data.csv\")\n",
    "enron4_preprocessed = pd.read_csv(\"./csv/preprocessed_enron4_data.csv\")\n",
    "enron5_preprocessed = pd.read_csv(\"./csv/preprocessed_enron5_data.csv\")\n",
    "enron6_preprocessed = pd.read_csv(\"./csv/preprocessed_enron6_data.csv\")\n",
    "merged_enron_preprocessed = pd.read_csv(\"./csv/preprocessed_merged_enron_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "918cf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "enron1_preprocessed_X, enron1_preprocessed_y = enron1_preprocessed[\"Text\"], enron1_preprocessed[\"Label\"]\n",
    "enron2_preprocessed_X, enron2_preprocessed_y = enron2_preprocessed[\"Text\"], enron2_preprocessed[\"Label\"]\n",
    "enron3_preprocessed_X, enron3_preprocessed_y = enron3_preprocessed[\"Text\"], enron3_preprocessed[\"Label\"]\n",
    "enron4_preprocessed_X, enron4_preprocessed_y = enron4_preprocessed[\"Text\"], enron4_preprocessed[\"Label\"]\n",
    "enron5_preprocessed_X, enron5_preprocessed_y = enron5_preprocessed[\"Text\"], enron5_preprocessed[\"Label\"]\n",
    "enron6_preprocessed_X, enron6_preprocessed_y = enron6_preprocessed[\"Text\"], enron6_preprocessed[\"Label\"]\n",
    "merged_enron_preprocessed_X, merged_enron_preprocessed_y = merged_enron_preprocessed[\"Text\"], merged_enron_preprocessed[\"Label\"]\n",
    "\n",
    "enron1_preprocessed_X = enron1_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "enron2_preprocessed_X = enron2_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "enron3_preprocessed_X = enron3_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "enron4_preprocessed_X = enron4_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "enron5_preprocessed_X = enron5_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "enron6_preprocessed_X = enron6_preprocessed_X.apply(lambda x: ast.literal_eval(x))\n",
    "merged_enron_preprocessed_X = merged_enron_preprocessed_X.apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5610b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(enron1_preprocessed_y))\n",
    "enron1_preprocessed_y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6440f622",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def save_preprocessed_data(preprocessed_X, preprocessed_y, X_name=\"X name\"):\n",
    "    joblib.dump({\n",
    "        \"features\": preprocessed_X,\n",
    "        \"labels\": preprocessed_y\n",
    "    }, f\"./preprocess/{X_name}.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5766e2",
   "metadata": {},
   "source": [
    "# Import preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e252d01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../Handlers/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c507c80d",
   "metadata": {},
   "source": [
    "# Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e38e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocessing\n",
    "\n",
    "enron1_lemmatized_X = enron1_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "enron2_lemmatized_X = enron2_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "enron3_lemmatized_X = enron3_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "enron4_lemmatized_X = enron4_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "enron5_lemmatized_X = enron5_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "enron6_lemmatized_X = enron6_preprocessed_X.apply(preprocessing.lemmatizing)\n",
    "merged_enron_lemmatized_X = merged_enron_preprocessed_X.apply(preprocessing.lemmatizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21c6b66",
   "metadata": {},
   "source": [
    "# Lemmatizing + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65143a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer shape for Enron1: (5172, 8364)\n",
      "CountVectorizer shape for Enron2: (5857, 10106)\n",
      "CountVectorizer shape for Enron3: (5512, 13967)\n",
      "CountVectorizer shape for Enron4: (5999, 17153)\n",
      "CountVectorizer shape for Enron5: (5175, 9898)\n",
      "CountVectorizer shape for Enron6: (6000, 14210)\n",
      "CountVectorizer shape for Merged Enron: (33715, 37087)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "\n",
    "enron1_lemmatized_countvec_X = preprocessing.vectorizing(enron1_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron1:\", enron1_lemmatized_countvec_X.shape)\n",
    "\n",
    "enron2_lemmatized_countvec_X = preprocessing.vectorizing(enron2_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron2:\", enron2_lemmatized_countvec_X.shape)\n",
    "\n",
    "enron3_lemmatized_countvec_X = preprocessing.vectorizing(enron3_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron3:\", enron3_lemmatized_countvec_X.shape)\n",
    "\n",
    "enron4_lemmatized_countvec_X = preprocessing.vectorizing(enron4_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron4:\", enron4_lemmatized_countvec_X.shape)\n",
    "\n",
    "enron5_lemmatized_countvec_X = preprocessing.vectorizing(enron5_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron5:\", enron5_lemmatized_countvec_X.shape)\n",
    "\n",
    "enron6_lemmatized_countvec_X = preprocessing.vectorizing(enron6_lemmatized_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron6:\", enron6_lemmatized_countvec_X.shape)\n",
    "\n",
    "merged_enron_lemmatized_countvec_X = preprocessing.vectorizing(merged_enron_lemmatized_X, \"countvectorizer\", min_df=5)\n",
    "\n",
    "print(\"CountVectorizer shape for Merged Enron:\", merged_enron_lemmatized_countvec_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81e7ac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preprocessed_data(enron1_lemmatized_countvec_X, enron1_preprocessed_y, \"enron1_lemmatized_countvec\")\n",
    "save_preprocessed_data(enron2_lemmatized_countvec_X, enron2_preprocessed_y, \"enron2_lemmatized_countvec\")\n",
    "save_preprocessed_data(enron3_lemmatized_countvec_X, enron3_preprocessed_y, \"enron3_lemmatized_countvec\")\n",
    "save_preprocessed_data(enron4_lemmatized_countvec_X, enron4_preprocessed_y, \"enron4_lemmatized_countvec\")\n",
    "save_preprocessed_data(enron5_lemmatized_countvec_X, enron5_preprocessed_y, \"enron5_lemmatized_countvec\")\n",
    "save_preprocessed_data(enron6_lemmatized_countvec_X, enron6_preprocessed_y, \"enron6_lemmatized_countvec\")\n",
    "save_preprocessed_data(merged_enron_lemmatized_countvec_X, merged_enron_preprocessed_y, \"enron_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f342c23",
   "metadata": {},
   "source": [
    "# Lemmatizing + TF-IDF Vectoizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eda25880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape for Enron1: (5172, 8364)\n",
      "TF-IDF shape for Enron2: (5857, 10106)\n",
      "TF-IDF shape for Enron3: (5512, 13967)\n",
      "TF-IDF shape for Enron4: (5999, 17153)\n",
      "TF-IDF shape for Enron5: (5175, 9898)\n",
      "TF-IDF shape for Enron6: (6000, 14210)\n",
      "TF-IDF shape for Merged Enron: (33715, 32780)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "\n",
    "enron1_lemmatized_tfidf_X = preprocessing.vectorizing(enron1_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron1:\", enron1_lemmatized_tfidf_X.shape)\n",
    "\n",
    "enron2_lemmatized_tfidf_X = preprocessing.vectorizing(enron2_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron2:\", enron2_lemmatized_tfidf_X.shape)\n",
    "\n",
    "enron3_lemmatized_tfidf_X = preprocessing.vectorizing(enron3_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron3:\", enron3_lemmatized_tfidf_X.shape)\n",
    "\n",
    "enron4_lemmatized_tfidf_X = preprocessing.vectorizing(enron4_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron4:\", enron4_lemmatized_tfidf_X.shape)\n",
    "\n",
    "enron5_lemmatized_tfidf_X = preprocessing.vectorizing(enron5_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron5:\", enron5_lemmatized_tfidf_X.shape)\n",
    "\n",
    "enron6_lemmatized_tfidf_X = preprocessing.vectorizing(enron6_lemmatized_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron6:\", enron6_lemmatized_tfidf_X.shape)\n",
    "\n",
    "merged_enron_lemmatized_tfidf_X = preprocessing.vectorizing(merged_enron_lemmatized_X, \"tfidf\", min_df=6)\n",
    "\n",
    "print(\"TF-IDF shape for Merged Enron:\", merged_enron_lemmatized_tfidf_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef7a38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preprocessed_data(enron1_lemmatized_tfidf_X, enron1_preprocessed_y, \"enron1_lemmatized_tfidf\")\n",
    "save_preprocessed_data(enron2_lemmatized_tfidf_X, enron2_preprocessed_y, \"enron2_lemmatized_tfidf\")\n",
    "save_preprocessed_data(enron3_lemmatized_tfidf_X, enron3_preprocessed_y, \"enron3_lemmatized_tfidf\")\n",
    "save_preprocessed_data(enron4_lemmatized_tfidf_X, enron4_preprocessed_y, \"enron4_lemmatized_tfidf\")\n",
    "save_preprocessed_data(enron5_lemmatized_tfidf_X, enron5_preprocessed_y, \"enron5_lemmatized_tfidf\")\n",
    "save_preprocessed_data(enron6_lemmatized_tfidf_X, enron6_preprocessed_y, \"enron6_lemmatized_tfidf\")\n",
    "save_preprocessed_data(merged_enron_lemmatized_tfidf_X, merged_enron_preprocessed_y, \"enron_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf03cb4",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4eb34431",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron1_stemming_X = enron1_preprocessed_X.apply(preprocessing.stemming)\n",
    "enron2_stemming_X = enron2_preprocessed_X.apply(preprocessing.stemming)\n",
    "enron3_stemming_X = enron3_preprocessed_X.apply(preprocessing.stemming)\n",
    "enron4_stemming_X = enron4_preprocessed_X.apply(preprocessing.stemming)\n",
    "enron5_stemming_X = enron5_preprocessed_X.apply(preprocessing.stemming)\n",
    "enron6_stemming_X = enron6_preprocessed_X.apply(preprocessing.stemming)\n",
    "merged_enron_stemming_X = merged_enron_preprocessed_X.apply(preprocessing.stemming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f6ba21",
   "metadata": {},
   "source": [
    "# Stemming + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1aef743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer shape for Enron1: (5172, 7318)\n",
      "CountVectorizer shape for Enron2: (5857, 8092)\n",
      "CountVectorizer shape for Enron3: (5512, 11061)\n",
      "CountVectorizer shape for Enron4: (5999, 15175)\n",
      "CountVectorizer shape for Enron5: (5175, 8046)\n",
      "CountVectorizer shape for Enron6: (6000, 12311)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "\n",
    "enron1_stemming_countvec_X = preprocessing.vectorizing(enron1_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron1:\", enron1_stemming_countvec_X.shape)\n",
    "\n",
    "enron2_stemming_countvec_X = preprocessing.vectorizing(enron2_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron2:\", enron2_stemming_countvec_X.shape)\n",
    "\n",
    "enron3_stemming_countvec_X = preprocessing.vectorizing(enron3_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron3:\", enron3_stemming_countvec_X.shape)\n",
    "\n",
    "enron4_stemming_countvec_X = preprocessing.vectorizing(enron4_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron4:\", enron4_stemming_countvec_X.shape)\n",
    "\n",
    "enron5_stemming_countvec_X = preprocessing.vectorizing(enron5_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron5:\", enron5_stemming_countvec_X.shape)\n",
    "\n",
    "enron6_stemming_countvec_X = preprocessing.vectorizing(enron6_stemming_X, \"countvectorizer\")\n",
    "\n",
    "print(\"CountVectorizer shape for Enron6:\", enron6_stemming_countvec_X.shape)\n",
    "\n",
    "merged_enron_stemming_countvec_X = preprocessing.vectorizing(merged_enron_stemming_X, \"countvectorizer\", min_df=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb2d49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preprocessed_data(enron1_stemming_countvec_X, enron1_preprocessed_y, \"enron1_stemmed_countvec\")\n",
    "save_preprocessed_data(enron2_stemming_countvec_X, enron2_preprocessed_y, \"enron2_stemmed_countvec\")\n",
    "save_preprocessed_data(enron3_stemming_countvec_X, enron3_preprocessed_y, \"enron3_stemmed_countvec\")\n",
    "save_preprocessed_data(enron4_stemming_countvec_X, enron4_preprocessed_y, \"enron4_stemmed_countvec\")\n",
    "save_preprocessed_data(enron5_stemming_countvec_X, enron5_preprocessed_y, \"enron5_stemmed_countvec\")\n",
    "save_preprocessed_data(enron6_stemming_countvec_X, enron6_preprocessed_y, \"enron6_stemmed_countvec\")\n",
    "save_preprocessed_data(merged_enron_stemming_countvec_X, merged_enron_preprocessed_y, \"enron_stemmed_countvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aa0b0b",
   "metadata": {},
   "source": [
    "# Stemming + TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a95643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape for Enron1: (5172, 7318)\n",
      "TF-IDF shape for Enron2: (5857, 8092)\n",
      "TF-IDF shape for Enron3: (5512, 11061)\n",
      "TF-IDF shape for Enron4: (5999, 15175)\n",
      "TF-IDF shape for Enron5: (5175, 8046)\n",
      "TF-IDF shape for Enron6: (6000, 12311)\n",
      "TF-IDF shape for Merged Enron: (33715, 27307)\n"
     ]
    }
   ],
   "source": [
    "import preprocessing\n",
    "\n",
    "enron1_stemming_tfidf_X = preprocessing.vectorizing(enron1_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron1:\", enron1_stemming_tfidf_X.shape)\n",
    "\n",
    "enron2_stemming_tfidf_X = preprocessing.vectorizing(enron2_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron2:\", enron2_stemming_tfidf_X.shape)\n",
    "\n",
    "enron3_stemming_tfidf_X = preprocessing.vectorizing(enron3_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron3:\", enron3_stemming_tfidf_X.shape)\n",
    "\n",
    "enron4_stemming_tfidf_X = preprocessing.vectorizing(enron4_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron4:\", enron4_stemming_tfidf_X.shape)\n",
    "\n",
    "enron5_stemming_tfidf_X = preprocessing.vectorizing(enron5_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron5:\", enron5_stemming_tfidf_X.shape)\n",
    "\n",
    "enron6_stemming_tfidf_X = preprocessing.vectorizing(enron6_stemming_X, \"tfidf\")\n",
    "\n",
    "print(\"TF-IDF shape for Enron6:\", enron6_stemming_tfidf_X.shape)\n",
    "\n",
    "merged_enron_stemming_tfidf_X = preprocessing.vectorizing(merged_enron_stemming_X, \"tfidf\", min_df=6)\n",
    "\n",
    "print(\"TF-IDF shape for Merged Enron:\", merged_enron_stemming_tfidf_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54c29031",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_preprocessed_data(enron1_stemming_tfidf_X, enron1_preprocessed_y, \"enron1_stemmed_tfidf\")\n",
    "save_preprocessed_data(enron2_stemming_tfidf_X, enron2_preprocessed_y, \"enron2_stemmed_tfidf\")\n",
    "save_preprocessed_data(enron3_stemming_tfidf_X, enron3_preprocessed_y, \"enron3_stemmed_tfidf\")\n",
    "save_preprocessed_data(enron4_stemming_tfidf_X, enron4_preprocessed_y, \"enron4_stemmed_tfidf\")\n",
    "save_preprocessed_data(enron5_stemming_tfidf_X, enron5_preprocessed_y, \"enron5_stemmed_tfidf\")\n",
    "save_preprocessed_data(enron6_stemming_tfidf_X, enron6_preprocessed_y, \"enron6_stemmed_tfidf\")\n",
    "save_preprocessed_data(merged_enron_stemming_tfidf_X, merged_enron_preprocessed_y, \"enron_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81715a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
