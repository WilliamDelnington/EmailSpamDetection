{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3ece83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to E:/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../Handlers\")\n",
    "\n",
    "JSON_WRITE_MODE = \"overwrite\"\n",
    "\n",
    "import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68f92a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Date</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>Received</th>\n",
       "      <th>Content-Type</th>\n",
       "      <th>Body</th>\n",
       "      <th>Is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Re: New Sequences Window</td>\n",
       "      <td>Thu, 22 Aug 2002 18:26:25 +0700</td>\n",
       "      <td>['Robert Elz &lt;kre@munnari.OZ.AU&gt;']</td>\n",
       "      <td>['Chris Garrigues &lt;cwg-dated-1030377287.06fa6d...</td>\n",
       "      <td>['from localhost (localhost [127.0.0.1])\\tby p...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>Date:        Wed, 21 Aug 2002 10:54:46 -05...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[zzzzteana] RE: Alexander</td>\n",
       "      <td>Thu, 22 Aug 2002 12:46:18 +0100</td>\n",
       "      <td>['Steve Burt &lt;Steve_Burt@cursor-system.com&gt;']</td>\n",
       "      <td>['\"\\'zzzzteana@yahoogroups.com\\'\" &lt;zzzzteana@y...</td>\n",
       "      <td>['from localhost (localhost [127.0.0.1])\\tby p...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>Martin A posted:\\nTassos Papadopoulos, the Gre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[zzzzteana] Moscow bomber</td>\n",
       "      <td>Thu, 22 Aug 2002 13:52:38 +0100</td>\n",
       "      <td>['Tim Chapman &lt;timc@2ubh.com&gt;']</td>\n",
       "      <td>['zzzzteana &lt;zzzzteana@yahoogroups.com&gt;']</td>\n",
       "      <td>['from localhost (localhost [127.0.0.1])\\tby p...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>Man Threatens Explosion In Moscow \\n\\nThursday...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[IRR] Klez: The Virus That  Won't Die</td>\n",
       "      <td>Thu, 22 Aug 2002 09:15:25 -0400</td>\n",
       "      <td>['Monty Solomon &lt;monty@roscom.com&gt;']</td>\n",
       "      <td>['undisclosed-recipient:;']</td>\n",
       "      <td>['from localhost (localhost [127.0.0.1])\\tby p...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>Klez: The Virus That Won't Die\\n \\nAlready the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Re: Insert signature</td>\n",
       "      <td>Thu, 22 Aug 2002 23:36:32 +1000</td>\n",
       "      <td>['Tony Nugent &lt;tony@linuxworks.com.au&gt;']</td>\n",
       "      <td>['Exmh Users Mailing List &lt;exmh-users@example....</td>\n",
       "      <td>['from localhost (localhost [127.0.0.1])\\tby p...</td>\n",
       "      <td>text/plain</td>\n",
       "      <td>On Wed Aug 21 2002 at 15:46, Ulises Ponce wrot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Subject                             Date  \\\n",
       "0               Re: New Sequences Window  Thu, 22 Aug 2002 18:26:25 +0700   \n",
       "1              [zzzzteana] RE: Alexander  Thu, 22 Aug 2002 12:46:18 +0100   \n",
       "2              [zzzzteana] Moscow bomber  Thu, 22 Aug 2002 13:52:38 +0100   \n",
       "3  [IRR] Klez: The Virus That  Won't Die  Thu, 22 Aug 2002 09:15:25 -0400   \n",
       "4                   Re: Insert signature  Thu, 22 Aug 2002 23:36:32 +1000   \n",
       "\n",
       "                                            From  \\\n",
       "0             ['Robert Elz <kre@munnari.OZ.AU>']   \n",
       "1  ['Steve Burt <Steve_Burt@cursor-system.com>']   \n",
       "2                ['Tim Chapman <timc@2ubh.com>']   \n",
       "3           ['Monty Solomon <monty@roscom.com>']   \n",
       "4       ['Tony Nugent <tony@linuxworks.com.au>']   \n",
       "\n",
       "                                                  To  \\\n",
       "0  ['Chris Garrigues <cwg-dated-1030377287.06fa6d...   \n",
       "1  ['\"\\'zzzzteana@yahoogroups.com\\'\" <zzzzteana@y...   \n",
       "2          ['zzzzteana <zzzzteana@yahoogroups.com>']   \n",
       "3                        ['undisclosed-recipient:;']   \n",
       "4  ['Exmh Users Mailing List <exmh-users@example....   \n",
       "\n",
       "                                            Received Content-Type  \\\n",
       "0  ['from localhost (localhost [127.0.0.1])\\tby p...   text/plain   \n",
       "1  ['from localhost (localhost [127.0.0.1])\\tby p...   text/plain   \n",
       "2  ['from localhost (localhost [127.0.0.1])\\tby p...   text/plain   \n",
       "3  ['from localhost (localhost [127.0.0.1])\\tby p...   text/plain   \n",
       "4  ['from localhost (localhost [127.0.0.1])\\tby p...   text/plain   \n",
       "\n",
       "                                                Body  Is_spam  \n",
       "0      Date:        Wed, 21 Aug 2002 10:54:46 -05...        0  \n",
       "1  Martin A posted:\\nTassos Papadopoulos, the Gre...        0  \n",
       "2  Man Threatens Explosion In Moscow \\n\\nThursday...        0  \n",
       "3  Klez: The Virus That Won't Die\\n \\nAlready the...        0  \n",
       "4  On Wed Aug 21 2002 at 15:46, Ulises Ponce wrot...        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = pd.read_csv(\"./SpamAssassin.csv\")\n",
    "\n",
    "csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3436b2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [date, DATE, TIME, chris, garrigues, messageid...\n",
       "1       [martin, posted, tassos, papadopoulos, greek, ...\n",
       "2       [man, threatens, explosion, moscow, thursday, ...\n",
       "3       [klez, virus, wont, die, already, prolific, vi...\n",
       "4       [wed, DATE, TIME, ulises, ponce, wrote, hi, co...\n",
       "                              ...                        \n",
       "4193    [preferred, nonsmoker, doctor, ordered, case, ...\n",
       "4194    [dear, subscriber, could, show, way, get, visi...\n",
       "4195    [midsummer, customer, appreciation, sale, expr...\n",
       "4196    [attnsirmadan, strictly, confidential, pleased...\n",
       "4197    [mv, efaeefcdfdcbaPHONENUMefaeefcdfdcba, mv, e...\n",
       "Name: Body, Length: 4198, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocession = partial(\n",
    "    preprocessing.preprocess_text,\n",
    "    remove_numbers=True\n",
    ")\n",
    "\n",
    "preprocessed_data = csv_file[\"Body\"].apply(preprocession)\n",
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77810663",
   "metadata": {},
   "source": [
    "## Stemming + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9950543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traintest import ClassificationModel, models, add_to_json_array\n",
    "\n",
    "metric_results = []\n",
    "\n",
    "def train_and_evaluate_model(X, y, dataset_name, m=None, mode=\"grid\"):\n",
    "    print(f\"{dataset_name} classification report\")\n",
    "    print(\"=========================================\")\n",
    "    if m is None:\n",
    "        for model in models:\n",
    "            classification_model = ClassificationModel(model, dataset_name)\n",
    "            classification_model.train_with_finding_best_parameters(X, y, save_model=True, mode=mode, n_jobs=6, cv=4)\n",
    "            classification_model.get_best_estimator(put_right_in_the_model=True)\n",
    "            print(f\"{model.__class__.__name__} classification report\")\n",
    "            metrics = classification_model.evaluate(detailed=True)\n",
    "            metric_results.append(metrics)\n",
    "            print(metrics)\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        classification_model = ClassificationModel(m, dataset_name)\n",
    "        classification_model.train_with_finding_best_parameters(X, y, save_model=True, mode=mode, n_jobs=6, cv=4)\n",
    "        classification_model.get_best_estimator(put_right_in_the_model=True)\n",
    "        print(f\"{m.__class__.__name__} classification report\")\n",
    "        metrics = classification_model.evaluate(detailed=True)\n",
    "        metric_results.append(metrics)\n",
    "        print(metrics)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8216cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_assassin_stemming = preprocessed_data.apply(preprocessing.stemming)\n",
    "spam_assassin_stemming_countvec = preprocessing.vectorizing(spam_assassin_stemming, \"countvectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446d48ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_assassin_stemming_countvec classification report\n",
      "=========================================\n",
      "The best estimator for SVM of dataset spam_assassin_stemming_countvec is: \n",
      "SVC(C=0.1, kernel='linear')\n",
      "SVC classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9821278938925998, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.9820944920324062, 'macro_precision': 0.981649069884364, 'macro_recall': 0.9764588859416445, 'macro_f1': 0.9789991249635401, 'roc_auc': 0.9764588859416448}, 'confusion_matrix': array([[575,   5],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9687311992735116}\n",
      "\n",
      "\n",
      "The best estimator for Multinomial Naive Bayes of dataset spam_assassin_stemming_countvec is: \n",
      "MultinomialNB(fit_prior=False)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.969047619047619, 'weighted_precision': 0.9691028874496616, 'wighted_recall': 0.969047619047619, 'weighted_f1': 0.9688404990331839, 'macro_precision': 0.9698397994768962, 'macro_recall': 0.9574270557029179, 'macro_f1': 0.9633172986482492, 'roc_auc': 0.9574270557029178}, 'confusion_matrix': array([[573,   7],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'alpha': 1.0, 'fit_prior': False}, 'best_score': 0.9711174726147909}\n",
      "\n",
      "\n",
      "The best estimator for Bernoulli Naive Bayes of dataset spam_assassin_stemming_countvec is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9619047619047619, 'weighted_precision': 0.9627450037148095, 'wighted_recall': 0.9619047619047619, 'weighted_f1': 0.9613692033046872, 'macro_precision': 0.9683466157817937, 'macro_recall': 0.9427055702917773, 'macro_f1': 0.9542284219703576, 'roc_auc': 0.9427055702917772}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 28, 232]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9684381917248425}\n",
      "\n",
      "\n",
      "The best estimator for Random Forest of dataset spam_assassin_stemming_countvec is: \n",
      "RandomForestClassifier(min_samples_split=10)\n",
      "RandomForestClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9797619047619047, 'weighted_precision': 0.979827637465338, 'wighted_recall': 0.9797619047619047, 'weighted_f1': 0.9796615882018462, 'macro_precision': 0.9809962188597054, 'macro_recall': 0.971551724137931, 'macro_f1': 0.9760947771775432, 'roc_auc': 0.9715517241379309}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9746871275327771}\n",
      "\n",
      "\n",
      "The best estimator for Decision Tree of dataset spam_assassin_stemming_countvec is: \n",
      "DecisionTreeClassifier(criterion='entropy', min_samples_split=5)\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9345238095238095, 'weighted_precision': 0.9340953564349322, 'wighted_recall': 0.9345238095238095, 'weighted_f1': 0.9340471974743075, 'macro_precision': 0.9288220876487496, 'macro_recall': 0.9165119363395225, 'macro_f1': 0.9223152085634871, 'roc_auc': 0.9165119363395225}, 'confusion_matrix': array([[559,  21],\n",
      "       [ 34, 226]], dtype=int64), 'best_parameters': {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}, 'best_score': 0.9309062659628808}\n",
      "\n",
      "\n",
      "The best estimator for AdaBoost of dataset spam_assassin_stemming_countvec is: \n",
      "AdaBoostClassifier(n_estimators=200)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9678571428571429, 'weighted_precision': 0.9677822727892473, 'wighted_recall': 0.9678571428571429, 'weighted_f1': 0.9678053418746052, 'macro_precision': 0.963789202501485, 'macro_recall': 0.9608090185676392, 'macro_f1': 0.96227990373725, 'roc_auc': 0.9608090185676392}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 15, 245]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9642662040978489}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.96754533 0.96992735 0.95057041 0.94193413        nan        nan\n",
      "        nan        nan 0.97319939        nan 0.95057041 0.94193413\n",
      " 0.97320045 0.97409366 0.95057041 0.94193413        nan        nan\n",
      "        nan        nan 0.97319939        nan 0.95027279 0.94163616\n",
      " 0.96962618 0.97022213 0.95027279 0.94193413        nan        nan\n",
      "        nan        nan 0.97319939        nan 0.95057041 0.94193413]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.9768115  0.97695377 0.97182952 0.96729556        nan        nan\n",
      "        nan        nan 0.96710654        nan 0.97182952 0.96729556\n",
      " 0.96379597 0.96551625 0.97182952 0.96729556        nan        nan\n",
      "        nan        nan 0.96710654        nan 0.9718025  0.9663563\n",
      " 0.9538097  0.95468078 0.9718025  0.96729556        nan        nan\n",
      "        nan        nan 0.96710654        nan 0.97182952 0.96729556]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.92613356 0.93317272 0.87952496 0.85753336        nan        nan\n",
      "        nan        nan 0.95340067        nan 0.87952496 0.85753336\n",
      " 0.95692488 0.95780208 0.87952496 0.85753336        nan        nan\n",
      "        nan        nan 0.95340067        nan 0.87864468 0.85753336\n",
      " 0.95693415 0.95781443 0.87864468 0.85753336        nan        nan\n",
      "        nan        nan 0.95340067        nan 0.87952496 0.85753336]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.95073674 0.95451713 0.92335516 0.90903183        nan        nan\n",
      "        nan        nan 0.96015493        nan 0.92335516 0.90903183\n",
      " 0.96027264 0.96158524 0.92335516 0.90903183        nan        nan\n",
      "        nan        nan 0.96015493        nan 0.92285341 0.90860358\n",
      " 0.95518805 0.95606371 0.92285341 0.90903183        nan        nan\n",
      "        nan        nan 0.96015493        nan 0.92335516 0.90903183]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset spam_assassin_stemming_countvec is: \n",
      "LogisticRegression(C=1, solver='liblinear')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9785714285714285, 'weighted_precision': 0.9785930245113919, 'wighted_recall': 0.9785714285714285, 'weighted_f1': 0.9784774033757339, 'macro_precision': 0.9790249433106576, 'macro_recall': 0.9706896551724138, 'macro_f1': 0.9747163955479452, 'roc_auc': 0.9706896551724139}, 'confusion_matrix': array([[575,   5],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9740936630909813}\n",
      "\n",
      "\n",
      "The best estimator for K-nearest Neighbors of dataset spam_assassin_stemming_countvec is: \n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.8630952380952381, 'weighted_precision': 0.8994506814982661, 'wighted_recall': 0.8630952380952381, 'weighted_f1': 0.8677824418867074, 'macro_precision': 0.8440519105984139, 'macro_recall': 0.8955570291777188, 'macro_f1': 0.8534976303317536, 'roc_auc': 0.8955570291777188}, 'confusion_matrix': array([[470, 110],\n",
      "       [  5, 255]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.8156659713945174}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "208 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "208 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 149, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95890516 0.95473317        nan 0.97052011        nan 0.96396468\n",
      " 0.96307324        nan        nan        nan 0.97081808        nan\n",
      " 0.96099098        nan 0.9422314         nan 0.94848353        nan\n",
      "        nan 0.9603929  0.96158905        nan 0.96039361        nan\n",
      "        nan        nan 0.94014877        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.9595004  0.95682502\n",
      " 0.96545668        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.95622481 0.96545952        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.93108006 0.94440128        nan 0.9719143         nan 0.9519476\n",
      " 0.94485575        nan        nan        nan 0.97454973        nan\n",
      " 0.94624868        nan 0.93356523        nan 0.92594494        nan\n",
      "        nan 0.93663427 0.97191647        nan 0.9495554         nan\n",
      "        nan        nan 0.9448084         nan        nan        nan\n",
      "        nan        nan        nan        nan 0.94027272 0.95914644\n",
      " 0.94902132        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.92465711 0.95717103        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94902088 0.92083024        nan 0.94019335        nan 0.94109526\n",
      " 0.94637386        nan        nan        nan 0.9384575         nan\n",
      " 0.93844823        nan 0.89363726        nan 0.92175686        nan\n",
      "        nan 0.94725105 0.91294477        nan 0.93317581        nan\n",
      "        nan        nan 0.87428651        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.94021497 0.91120274\n",
      " 0.94901779        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.9481406  0.94022424        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.93980704 0.93225308        nan 0.95575469        nan 0.94642953\n",
      " 0.94550315        nan        nan        nan 0.95604394        nan\n",
      " 0.94214953        nan 0.91251788        nan 0.9235955         nan\n",
      "        nan 0.9418095  0.94150413        nan 0.94104781        nan\n",
      "        nan        nan 0.90778509        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.94022637 0.93443707\n",
      " 0.94898065        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.93613079 0.94840137        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Stochastic Gradient Descent of dataset spam_assassin_stemming_countvec is: \n",
      "SGDClassifier(alpha=0.01, loss='log_loss')\n",
      "SGDClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9666666666666667, 'weighted_precision': 0.9672222222222221, 'wighted_recall': 0.9666666666666667, 'weighted_f1': 0.9662824858757062, 'macro_precision': 0.9716666666666667, 'macro_recall': 0.9503978779840849, 'macro_f1': 0.960135593220339, 'roc_auc': 0.9503978779840848}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 24, 236]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'log_loss', 'learning_rate': 'optimal', 'alpha': 0.01}, 'best_score': 0.9708180799137295}\n",
      "\n",
      "\n",
      "The best estimator for Gradient Boosting of dataset spam_assassin_stemming_countvec is: \n",
      "GradientBoostingClassifier(max_depth=7, min_samples_leaf=4, n_estimators=200)\n",
      "GradientBoostingClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9785714285714285, 'weighted_precision': 0.9790366691290885, 'wighted_recall': 0.9785714285714285, 'weighted_f1': 0.978377065111759, 'macro_precision': 0.9836890747056882, 'macro_recall': 0.9664456233421751, 'macro_f1': 0.9744897959183674, 'roc_auc': 0.9664456233421752}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.964861442193087}\n",
      "\n",
      "\n",
      "The best estimator for Perceptron of dataset spam_assassin_stemming_countvec is: \n",
      "Perceptron(penalty='elasticnet')\n",
      "Perceptron classification report\n",
      "{'dataset': 'spam_assassin_stemming_countvec', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9654761904761905, 'weighted_precision': 0.9654460238828168, 'wighted_recall': 0.9654761904761905, 'weighted_f1': 0.9652652962386051, 'macro_precision': 0.9650072370701078, 'macro_recall': 0.9537798408488064, 'macro_f1': 0.9591301911452104, 'roc_auc': 0.9537798408488064}, 'confusion_matrix': array([[571,   9],\n",
      "       [ 20, 240]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}, 'best_score': 0.9666485754015551}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(spam_assassin_stemming_countvec, csv_file[\"Is_spam\"], \"spam_assassin_stemming_countvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dfa321",
   "metadata": {},
   "source": [
    "## Stemming + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e40f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_assassin_stemming_tfidf = preprocessing.vectorizing(spam_assassin_stemming, \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c61b88c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_assassin_stemmed_tfidf classification report\n",
      "=========================================\n",
      "The best estimator for SVM of dataset spam_assassin_stemmed_tfidf is: \n",
      "SVC(C=10, kernel='linear')\n",
      "SVC classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.9773371649518776, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9773444998376851, 'macro_precision': 0.9750018354012187, 'macro_recall': 0.971949602122016, 'macro_f1': 0.9734562285558426, 'roc_auc': 0.971949602122016}, 'confusion_matrix': array([[572,   8],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9734962966116125}\n",
      "\n",
      "\n",
      "The best estimator for Multinomial Naive Bayes of dataset spam_assassin_stemmed_tfidf is: \n",
      "MultinomialNB(alpha=0.1, fit_prior=False)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.969047619047619, 'weighted_precision': 0.9689614310156622, 'wighted_recall': 0.969047619047619, 'weighted_f1': 0.9689466004714518, 'macro_precision': 0.9666630834968155, 'macro_recall': 0.9606100795755967, 'macro_f1': 0.9635589430758655, 'roc_auc': 0.9606100795755967}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 16, 244]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9711188915375446}\n",
      "\n",
      "\n",
      "The best estimator for Bernoulli Naive Bayes of dataset spam_assassin_stemmed_tfidf is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9619047619047619, 'weighted_precision': 0.9627450037148095, 'wighted_recall': 0.9619047619047619, 'weighted_f1': 0.9613692033046872, 'macro_precision': 0.9683466157817937, 'macro_recall': 0.9427055702917773, 'macro_f1': 0.9542284219703576, 'roc_auc': 0.9427055702917772}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 28, 232]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9684381917248425}\n",
      "\n",
      "\n",
      "The best estimator for Random Forest of dataset spam_assassin_stemmed_tfidf is: \n",
      "RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
      "RandomForestClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9823257254301228, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.98203377391652, 'macro_precision': 0.9849856277903493, 'macro_recall': 0.9732758620689654, 'macro_f1': 0.9788604436957985, 'roc_auc': 0.9732758620689654}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.974092598898916}\n",
      "\n",
      "\n",
      "The best estimator for Decision Tree of dataset spam_assassin_stemmed_tfidf is: \n",
      "DecisionTreeClassifier()\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9261904761904762, 'weighted_precision': 0.9261904761904762, 'wighted_recall': 0.9261904761904762, 'weighted_f1': 0.9261904761904762, 'macro_precision': 0.9136604774535808, 'macro_recall': 0.9136604774535808, 'macro_f1': 0.9136604774535808, 'roc_auc': 0.9136604774535808}, 'confusion_matrix': array([[549,  31],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}, 'best_score': 0.9204913729496565}\n",
      "\n",
      "\n",
      "The best estimator for AdaBoost of dataset spam_assassin_stemmed_tfidf is: \n",
      "AdaBoostClassifier(n_estimators=200)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9761904761904762, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9760860037508153, 'macro_precision': 0.9761904761904762, 'macro_recall': 0.9679045092838197, 'macro_f1': 0.9719071061643836, 'roc_auc': 0.9679045092838195}, 'confusion_matrix': array([[574,   6],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9574124524660877}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.85943867 0.86211937 0.8591407  0.86033189        nan        nan\n",
      "        nan        nan 0.97796413        nan 0.97647391 0.97915532\n",
      " 0.96099204 0.96188561 0.96099204 0.96188561        nan        nan\n",
      "        nan        nan 0.97796413        nan 0.97766687 0.9782621\n",
      " 0.97320116 0.97320116 0.97320116 0.97320116        nan        nan\n",
      "        nan        nan 0.97796413        nan 0.9776658  0.97856008]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.99405113 0.99412124 0.99405113 0.9940771         nan        nan\n",
      "        nan        nan 0.97416536        nan 0.96333998 0.96679531\n",
      " 0.9837571  0.98381511 0.9837571  0.98381511        nan        nan\n",
      "        nan        nan 0.97416536        nan 0.96265312 0.96505964\n",
      " 0.98256992 0.98256992 0.98256992 0.98256992        nan        nan\n",
      "        nan        nan 0.97416536        nan 0.96346779 0.96427468]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.5884019  0.59632135 0.58752162 0.59103966        nan        nan\n",
      "        nan        nan 0.96044292        nan 0.96747282 0.97186496\n",
      " 0.89975599 0.90239375 0.89975599 0.90239375        nan        nan\n",
      "        nan        nan 0.96044292        nan 0.97186805 0.97098777\n",
      " 0.93756795 0.93756795 0.93756795 0.93756795        nan        nan\n",
      "        nan        nan 0.96044292        nan 0.97099086 0.97274524]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.73907164 0.74532197 0.73836884 0.74114433        nan        nan\n",
      "        nan        nan 0.96720031        nan 0.96535625 0.96929755\n",
      " 0.93977479 0.94122814 0.93977479 0.94122814        nan        nan\n",
      "        nan        nan 0.96720031        nan 0.96718582 0.96799041\n",
      " 0.95947153 0.95947153 0.95947153 0.95947153        nan        nan\n",
      "        nan        nan 0.96720031        nan 0.96715334 0.96847597]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset spam_assassin_stemmed_tfidf is: \n",
      "LogisticRegression(C=0.1, penalty=None, solver='saga')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845220139337786, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844818930947521, 'macro_precision': 0.9844645550527904, 'macro_recall': 0.9792440318302387, 'macro_f1': 0.9817992416350682, 'roc_auc': 0.9792440318302388}, 'confusion_matrix': array([[576,   4],\n",
      "       [  9, 251]], dtype=int64), 'best_parameters': {'C': 0.1, 'penalty': None, 'solver': 'saga'}, 'best_score': 0.979155315284636}\n",
      "\n",
      "\n",
      "The best estimator for K-nearest Neighbors of dataset spam_assassin_stemmed_tfidf is: \n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.5607142857142857, 'weighted_precision': 0.8184192595957303, 'wighted_recall': 0.5607142857142857, 'weighted_f1': 0.5494191544640991, 'macro_precision': 0.7066772655007949, 'macro_recall': 0.681896551724138, 'macro_f1': 0.5592143902366187, 'roc_auc': 0.681896551724138}, 'confusion_matrix': array([[211, 369],\n",
      "       [  0, 260]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.5175761961518816}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "208 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "208 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 149, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95979873 0.97141509        nan 0.85884556        nan 0.96277846\n",
      " 0.97141474        nan        nan        nan 0.78409423        nan\n",
      " 0.93359406        nan 0.9053018         nan 0.97111712        nan\n",
      "        nan 0.97111605 0.72930643        nan 0.97052153        nan\n",
      "        nan        nan 0.94699508        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97200998 0.68403854\n",
      " 0.97260699        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96396929 0.94699543        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.93493645 0.98070751        nan 0.99400651        nan 0.97830489\n",
      " 0.98161249        nan        nan        nan 0.99557522        nan\n",
      " 0.98616767        nan 0.98346528        nan 0.98160523        nan\n",
      "        nan 0.97543909 0.99561404        nan 0.97983341        nan\n",
      "        nan        nan 0.9858617         nan        nan        nan\n",
      "        nan        nan        nan        nan 0.98251487 1.\n",
      " 0.97117734        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94666034 0.98693486        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94813442 0.934053          nan 0.58665369        nan 0.91030702\n",
      " 0.93316963        nan        nan        nan 0.36409377        nan\n",
      " 0.81533543        nan 0.73265691        nan 0.93228935        nan\n",
      "        nan 0.93844823 0.20141154        nan 0.93228935        nan\n",
      "        nan        nan 0.85578206        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.93404991 0.06683963\n",
      " 0.94724796        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94724796 0.85489869        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94111876 0.95673094        nan 0.73770956        nan 0.94302941\n",
      " 0.95668476        nan        nan        nan 0.53281529        nan\n",
      " 0.89245972        nan 0.83959556        nan 0.95620596        nan\n",
      "        nan 0.95653343 0.33458507        nan 0.95536026        nan\n",
      "        nan        nan 0.91613477        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.95758634 0.12525364\n",
      " 0.95897294        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94684568 0.91604795        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Stochastic Gradient Descent of dataset spam_assassin_stemmed_tfidf is: \n",
      "SGDClassifier()\n",
      "SGDClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9767827692728878, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9759455185966459, 'macro_precision': 0.9820475966721026, 'macro_recall': 0.9625994694960213, 'macro_f1': 0.9715907169285507, 'roc_auc': 0.9625994694960213}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.0001}, 'best_score': 0.97260698677564}\n",
      "\n",
      "\n",
      "The best estimator for Gradient Boosting of dataset spam_assassin_stemmed_tfidf is: \n",
      "GradientBoostingClassifier(max_depth=7, min_samples_leaf=4, n_estimators=200)\n",
      "GradientBoostingClassifier classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9754775247982022, 'wighted_recall': 0.975, 'weighted_f1': 0.9747580785465627, 'macro_precision': 0.9799718758401059, 'macro_recall': 0.9617374005305039, 'macro_f1': 0.9702042629524468, 'roc_auc': 0.961737400530504}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.958606830694137}\n",
      "\n",
      "\n",
      "The best estimator for Perceptron of dataset spam_assassin_stemmed_tfidf is: \n",
      "Perceptron(penalty='l2', tol=1e-05)\n",
      "Perceptron classification report\n",
      "{'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9678571428571429, 'weighted_precision': 0.9677822727892473, 'wighted_recall': 0.9678571428571429, 'weighted_f1': 0.9678053418746052, 'macro_precision': 0.963789202501485, 'macro_recall': 0.9608090185676392, 'macro_f1': 0.96227990373725, 'roc_auc': 0.9608090185676392}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 15, 245]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}, 'best_score': 0.9645641778761563}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(spam_assassin_stemming_tfidf, csv_file[\"Is_spam\"], \"spam_assassin_stemmed_tfidf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740b7bd",
   "metadata": {},
   "source": [
    "## Lemmatizing + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77619e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_assassin_lemmatizing = preprocessed_data.apply(preprocessing.lemmatizing)\n",
    "spam_assassin_lemmatizing_countvec = preprocessing.vectorizing(spam_assassin_lemmatizing, \"countvectorizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0104d991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_assassin_lemmatized_countvec classification report\n",
      "=========================================\n",
      "The best estimator for SVM of dataset spam_assassin_lemmatized_countvec is: \n",
      "SVC(C=0.1, kernel='linear')\n",
      "SVC classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845669600872919, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844646367895364, 'macro_precision': 0.985553258681175, 'macro_recall': 0.9781830238726791, 'macro_f1': 0.9817595975084814, 'roc_auc': 0.9781830238726792}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9726041489301323}\n",
      "\n",
      "\n",
      "The best estimator for Multinomial Naive Bayes of dataset spam_assassin_lemmatized_countvec is: \n",
      "MultinomialNB(alpha=0.5, fit_prior=False)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9738095238095238, 'weighted_precision': 0.9741825545269267, 'wighted_recall': 0.9738095238095238, 'weighted_f1': 0.9735719684699279, 'macro_precision': 0.9779128617009571, 'macro_recall': 0.9608753315649867, 'macro_f1': 0.9688208616780047, 'roc_auc': 0.9608753315649867}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'alpha': 0.5, 'fit_prior': False}, 'best_score': 0.972011039219025}\n",
      "\n",
      "\n",
      "The best estimator for Bernoulli Naive Bayes of dataset spam_assassin_lemmatized_countvec is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9595238095238096, 'weighted_precision': 0.9607923364445596, 'wighted_recall': 0.9595238095238096, 'weighted_f1': 0.9588490401498532, 'macro_precision': 0.9680410617059891, 'macro_recall': 0.9377984084880637, 'macro_f1': 0.9511373901617804, 'roc_auc': 0.9377984084880637}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9654612917872751}\n",
      "\n",
      "\n",
      "The best estimator for Random Forest of dataset spam_assassin_lemmatized_countvec is: \n",
      "RandomForestClassifier(min_samples_split=5, n_estimators=200)\n",
      "RandomForestClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9824455743067617, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.9820128720384474, 'macro_precision': 0.9861713240163581, 'macro_recall': 0.9722148541114058, 'macro_f1': 0.9788132386991328, 'roc_auc': 0.9722148541114058}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9752834298200806}\n",
      "\n",
      "\n",
      "The best estimator for Decision Tree of dataset spam_assassin_lemmatized_countvec is: \n",
      "DecisionTreeClassifier(max_depth=30)\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9273809523809524, 'weighted_precision': 0.9271739810980689, 'wighted_recall': 0.9273809523809524, 'weighted_f1': 0.9272639205315152, 'macro_precision': 0.9161355126776167, 'macro_recall': 0.9134615384615384, 'macro_f1': 0.9147805232582312, 'roc_auc': 0.9134615384615384}, 'confusion_matrix': array([[551,  29],\n",
      "       [ 32, 228]], dtype=int64), 'best_parameters': {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'gini'}, 'best_score': 0.9172154350417163}\n",
      "\n",
      "\n",
      "The best estimator for AdaBoost of dataset spam_assassin_lemmatized_countvec is: \n",
      "AdaBoostClassifier(n_estimators=100)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9630952380952381, 'weighted_precision': 0.9629697142844318, 'wighted_recall': 0.9630952380952381, 'weighted_f1': 0.9629541338827408, 'macro_precision': 0.9601005986088573, 'macro_recall': 0.9531167108753316, 'macro_f1': 0.9565036555971477, 'roc_auc': 0.9531167108753316}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 100}, 'best_score': 0.9624772972359386}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.96843748 0.96873475 0.95622552 0.94699472        nan        nan\n",
      "        nan        nan 0.97230476        nan 0.95622552 0.9466971\n",
      " 0.97558105 0.9755814  0.95622552 0.9466971         nan        nan\n",
      "        nan        nan 0.97230476        nan 0.95622552 0.94610151\n",
      " 0.97141296 0.97141296 0.95622552 0.94639913        nan        nan\n",
      "        nan        nan 0.97230476        nan 0.95622552 0.94580354]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.98049211 0.9786837  0.97329302 0.96704877        nan        nan\n",
      "        nan        nan 0.96216624        nan 0.97329302 0.96699797\n",
      " 0.96649002 0.96729018 0.97329302 0.96699797        nan        nan\n",
      "        nan        nan 0.96216624        nan 0.97329302 0.96691567\n",
      " 0.9547358  0.95556068 0.97329302 0.96604846        nan        nan\n",
      "        nan        nan 0.96216624        nan 0.97329302 0.96596254]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.92525019 0.92789103 0.89534532 0.87335063        nan        nan\n",
      "        nan        nan 0.95604151        nan 0.89534532 0.87247344\n",
      " 0.96130467 0.96042748 0.89534532 0.87247344        nan        nan\n",
      "        nan        nan 0.95604151        nan 0.89534532 0.87071596\n",
      " 0.96132011 0.96043983 0.89534532 0.87247344        nan        nan\n",
      "        nan        nan 0.95604151        nan 0.89534532 0.87071596]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.95196694 0.95253685 0.93265473 0.91773462        nan        nan\n",
      "        nan        nan 0.95901301        nan 0.93265473 0.91723588\n",
      " 0.96386878 0.96383017 0.93265473 0.91723588        nan        nan\n",
      "        nan        nan 0.95901301        nan 0.93265473 0.91622996\n",
      " 0.95793442 0.95790971 0.93265473 0.91681171        nan        nan\n",
      "        nan        nan 0.95901301        nan 0.93265473 0.91580595]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset spam_assassin_lemmatized_countvec is: \n",
      "LogisticRegression(C=1, solver='liblinear')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845669600872919, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844646367895364, 'macro_precision': 0.985553258681175, 'macro_recall': 0.9781830238726791, 'macro_f1': 0.9817595975084814, 'roc_auc': 0.9781830238726792}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9755814035983881}\n",
      "\n",
      "\n",
      "The best estimator for K-nearest Neighbors of dataset spam_assassin_lemmatized_countvec is: \n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.844047619047619, 'weighted_precision': 0.8913206123214636, 'wighted_recall': 0.844047619047619, 'weighted_f1': 0.8497148853167455, 'macro_precision': 0.8298272877376007, 'macro_recall': 0.8828249336870027, 'macro_f1': 0.8349707779499123, 'roc_auc': 0.8828249336870027}, 'confusion_matrix': array([[453, 127],\n",
      "       [  4, 256]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.8028626766558828}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "208 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "208 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 149, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95890339 0.93686893        nan 0.97587867        nan 0.96247588\n",
      " 0.96337015        nan        nan        nan 0.96903237        nan\n",
      " 0.96754143        nan 0.94491032        nan 0.95890587        nan\n",
      "        nan 0.96128576 0.96248226        nan 0.9657543         nan\n",
      "        nan        nan 0.94401463        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.96158231 0.96158763\n",
      " 0.96724062        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96188241 0.96635238        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.93132391 0.9262544         nan 0.97311608        nan 0.94087407\n",
      " 0.94261712        nan        nan        nan 0.98138832        nan\n",
      " 0.95754013        nan 0.95300515        nan 0.9404431         nan\n",
      "        nan 0.93908592 0.96848035        nan 0.95312717        nan\n",
      "        nan        nan 0.94163823        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.9423123  0.9666761\n",
      " 0.9463874         nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.93782012 0.96305293        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94902397 0.88484371        nan 0.95515505        nan 0.94899926\n",
      " 0.94989498        nan        nan        nan 0.92613356        nan\n",
      " 0.94637695        nan 0.88043921        nan 0.93844514        nan\n",
      "        nan 0.94724487 0.91909439        nan 0.94551211        nan\n",
      "        nan        nan 0.89013158        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.94461329 0.91822029\n",
      " 0.9577959         nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.95078144 0.9367062         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.93988872 0.90404493        nan 0.96402985        nan 0.94487733\n",
      " 0.94616473        nan        nan        nan 0.95290313        nan\n",
      " 0.95178621        nan 0.91499458        nan 0.93930799        nan\n",
      "        nan 0.94312399 0.94311289        nan 0.94913719        nan\n",
      "        nan        nan 0.91423213        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.94334147 0.94176867\n",
      " 0.95199559        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94410922 0.94950244        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Stochastic Gradient Descent of dataset spam_assassin_lemmatized_countvec is: \n",
      "SGDClassifier(alpha=0.01)\n",
      "SGDClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9767827692728878, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9759455185966459, 'macro_precision': 0.9820475966721026, 'macro_recall': 0.9625994694960213, 'macro_f1': 0.9715907169285507, 'roc_auc': 0.9625994694960213}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.01}, 'best_score': 0.9758786679153187}\n",
      "\n",
      "\n",
      "The best estimator for Gradient Boosting of dataset spam_assassin_lemmatized_countvec is: \n",
      "GradientBoostingClassifier(max_depth=7, min_samples_leaf=4, n_estimators=200)\n",
      "GradientBoostingClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.9777453838678329, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9771894028308606, 'macro_precision': 0.9816326530612245, 'macro_recall': 0.9655835543766578, 'macro_f1': 0.9731030124289024, 'roc_auc': 0.9655835543766578}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.9645613400306488}\n",
      "\n",
      "\n",
      "The best estimator for Perceptron of dataset spam_assassin_lemmatized_countvec is: \n",
      "Perceptron(penalty='l2')\n",
      "Perceptron classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9756613719962038, 'wighted_recall': 0.975, 'weighted_f1': 0.9747273900037075, 'macro_precision': 0.9812308203852895, 'macro_recall': 0.9606763925729443, 'macro_f1': 0.9701360637503619, 'roc_auc': 0.9606763925729443}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 20, 240]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}, 'best_score': 0.9603911260570974}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(spam_assassin_lemmatizing_countvec, csv_file[\"Is_spam\"], \"spam_assassin_lemmatized_countvec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42927584",
   "metadata": {},
   "source": [
    "## Lemmatizing + TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc223450",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_assassin_lemmatizing_tfidf = preprocessing.vectorizing(spam_assassin_lemmatizing, \"tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d1f9d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam_assassin_lemmatized_tfidf classification report\n",
      "=========================================\n",
      "The best estimator for SVM of dataset spam_assassin_lemmatized_tfidf is: \n",
      "SVC(C=10, kernel='sigmoid')\n",
      "SVC classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9749765748044577, 'wighted_recall': 0.975, 'weighted_f1': 0.9749866818021138, 'macro_precision': 0.9712285435177002, 'macro_recall': 0.9702254641909814, 'macro_f1': 0.9707248584785888, 'roc_auc': 0.9702254641909814}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}, 'best_score': 0.9758779584539418}\n",
      "\n",
      "\n",
      "The best estimator for Multinomial Naive Bayes of dataset spam_assassin_lemmatized_tfidf is: \n",
      "MultinomialNB(alpha=0.1, fit_prior=False)\n",
      "MultinomialNB classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9726190476190476, 'weighted_precision': 0.9725514137278843, 'wighted_recall': 0.9726190476190476, 'weighted_f1': 0.9725448877830226, 'macro_precision': 0.9703871292106586, 'macro_recall': 0.9653183023872679, 'macro_f1': 0.9677986582774282, 'roc_auc': 0.965318302387268}, 'confusion_matrix': array([[571,   9],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9729060247460128}\n",
      "\n",
      "\n",
      "The best estimator for Bernoulli Naive Bayes of dataset spam_assassin_lemmatized_tfidf is: \n",
      "BernoulliNB(alpha=0.1, fit_prior=False)\n",
      "BernoulliNB classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9595238095238096, 'weighted_precision': 0.9607923364445596, 'wighted_recall': 0.9595238095238096, 'weighted_f1': 0.9588490401498532, 'macro_precision': 0.9680410617059891, 'macro_recall': 0.9377984084880637, 'macro_f1': 0.9511373901617804, 'roc_auc': 0.9377984084880637}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9654612917872751}\n",
      "\n",
      "\n",
      "The best estimator for Random Forest of dataset spam_assassin_lemmatized_tfidf is: \n",
      "RandomForestClassifier(min_samples_split=5, n_estimators=50)\n",
      "RandomForestClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9847371113654521, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844292707276506, 'macro_precision': 0.9878396836075265, 'macro_recall': 0.9760610079575598, 'macro_f1': 0.9816790512030253, 'roc_auc': 0.9760610079575599}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 12, 248]], dtype=int64), 'best_parameters': {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9740911799761621}\n",
      "\n",
      "\n",
      "The best estimator for Decision Tree of dataset spam_assassin_lemmatized_tfidf is: \n",
      "DecisionTreeClassifier(min_samples_split=5)\n",
      "DecisionTreeClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9321428571428572, 'weighted_precision': 0.9330069113173171, 'wighted_recall': 0.9321428571428572, 'weighted_f1': 0.9324547945604019, 'macro_precision': 0.9176459482158088, 'macro_recall': 0.9253978779840849, 'macro_f1': 0.9213636863810379, 'roc_auc': 0.9253978779840847}, 'confusion_matrix': array([[547,  33],\n",
      "       [ 24, 236]], dtype=int64), 'best_parameters': {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}, 'best_score': 0.9189983114819229}\n",
      "\n",
      "\n",
      "The best estimator for AdaBoost of dataset spam_assassin_lemmatized_tfidf is: \n",
      "AdaBoostClassifier(n_estimators=100)\n",
      "AdaBoostClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9666666666666667, 'weighted_precision': 0.9665645463259074, 'wighted_recall': 0.9666666666666667, 'weighted_f1': 0.9665578774307942, 'macro_precision': 0.9638413372389885, 'macro_recall': 0.9578249336870026, 'macro_f1': 0.960755784850932, 'roc_auc': 0.9578249336870027}, 'confusion_matrix': array([[569,  11],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 100}, 'best_score': 0.9568196974856689}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "60 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 64, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1291, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 63, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\utils\\parallel.py\", line 123, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 521, in _logistic_regression_path\n",
      "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
      "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1216, in fit\n",
      "    self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1223, in _fit_liblinear\n",
      "    solver_type = _get_liblinear_solver_type(multi_class, penalty, loss, dual)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 1062, in _get_liblinear_solver_type\n",
      "    raise ValueError(\n",
      "ValueError: Unsupported set of arguments: The combination of penalty='None' and loss='logistic_regression' is not supported, Parameters: penalty=None, loss='logistic_regression', dual=False\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84990777 0.85288786 0.84990777 0.84990777        nan        nan\n",
      "        nan        nan 0.97736818        nan 0.97974984 0.98064306\n",
      " 0.9618849  0.9618849  0.9618849  0.9618849         nan        nan\n",
      "        nan        nan 0.97736818        nan 0.97945364 0.98094138\n",
      " 0.97260628 0.97260628 0.97260628 0.97230866        nan        nan\n",
      "        nan        nan 0.97736818        nan 0.97885663 0.97974949]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.99376787 0.993801   0.99376787 0.99376787        nan        nan\n",
      "        nan        nan 0.96832542        nan 0.96849229 0.97104191\n",
      " 0.98466311 0.98466311 0.98466311 0.98466311        nan        nan\n",
      "        nan        nan 0.96832542        nan 0.96764982 0.97026121\n",
      " 0.98081945 0.98081945 0.98081945 0.98081219        nan        nan\n",
      "        nan        nan 0.96832542        nan 0.96842405 0.9676848 ]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.56025451 0.56905733 0.56025451 0.56025451        nan        nan\n",
      "        nan        nan 0.96483815        nan 0.97185878 0.97185878\n",
      " 0.90151347 0.90151347 0.90151347 0.90151347        nan        nan\n",
      "        nan        nan 0.96483815        nan 0.97186496 0.97362244\n",
      " 0.93756795 0.93756795 0.93756795 0.93668767        nan        nan\n",
      "        nan        nan 0.96483815        nan 0.96922721 0.97273907]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.71621938 0.72352145 0.71621938 0.71621938        nan        nan\n",
      "        nan        nan 0.96649738        nan 0.97015481 0.97143912\n",
      " 0.94117993 0.94117993 0.94117993 0.94117993        nan        nan\n",
      "        nan        nan 0.96649738        nan 0.96971979 0.97191375\n",
      " 0.95858797 0.95858797 0.95858797 0.95810917        nan        nan\n",
      "        nan        nan 0.96649738        nan 0.9688012  0.97018398]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Logistic Regression of dataset spam_assassin_lemmatized_tfidf is: \n",
      "LogisticRegression(C=1, penalty=None, solver='saga')\n",
      "LogisticRegression classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9904761904761905, 'weighted_precision': 0.9905333932234581, 'wighted_recall': 0.9904761904761905, 'weighted_f1': 0.9904451078373697, 'macro_precision': 0.9920587998172583, 'macro_recall': 0.9856763925729444, 'macro_f1': 0.9887873671002663, 'roc_auc': 0.9856763925729444}, 'confusion_matrix': array([[579,   1],\n",
      "       [  7, 253]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': None, 'solver': 'saga'}, 'best_score': 0.9809413843010387}\n",
      "\n",
      "\n",
      "The best estimator for K-nearest Neighbors of dataset spam_assassin_lemmatized_tfidf is: \n",
      "KNeighborsClassifier(n_neighbors=3, weights='distance')\n",
      "KNeighborsClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.55, 'weighted_precision': 0.8166144200626959, 'wighted_recall': 0.55, 'weighted_f1': 0.5359508769131744, 'macro_precision': 0.7037617554858935, 'macro_recall': 0.6741379310344827, 'macro_f1': 0.547844314446995, 'roc_auc': 0.6741379310344828}, 'confusion_matrix': array([[202, 378],\n",
      "       [  0, 260]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.5095344514444634}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "208 fits failed out of a total of 280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "208 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 892, in fit\n",
      "    self._more_validate_params()\n",
      "  File \"e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\", line 149, in _more_validate_params\n",
      "    raise ValueError(\"eta0 must be > 0\")\n",
      "ValueError: eta0 must be > 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.96635202 0.97171307        nan 0.82906521        nan 0.96188419\n",
      " 0.97111712        nan        nan        nan 0.75401803        nan\n",
      " 0.92614791        nan 0.89636649        nan 0.97081914        nan\n",
      "        nan 0.97171307 0.69654705        nan 0.96843642        nan\n",
      "        nan        nan 0.94580425        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.97052188 0.67093514\n",
      " 0.97439306        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.96307679 0.9466971         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95048168 0.98162581        nan 0.99299381        nan 0.97918599\n",
      " 0.98160523        nan        nan        nan 0.99712644        nan\n",
      " 0.98688786        nan 0.98755042        nan 0.98075694        nan\n",
      "        nan 0.97448702 1.                nan 0.97967213        nan\n",
      "        nan        nan 0.98676972        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.98155802 1.\n",
      " 0.97815643        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94804213 0.98684437        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95076291 0.93404991        nan 0.49868112        nan 0.90678589\n",
      " 0.93228935        nan        nan        nan 0.27438226        nan\n",
      " 0.79247282        nan 0.70275204        nan 0.93228317        nan\n",
      "        nan 0.94108599 0.10377749        nan 0.92612738        nan\n",
      "        nan        nan 0.85138683        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.93053188 0.0281443\n",
      " 0.9454874         nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94285891 0.8540215         nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "e:\\Python Tests\\AI\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.95035367 0.95714107        nan 0.66391691        nan 0.94156052\n",
      " 0.95620596        nan        nan        nan 0.42978941        nan\n",
      " 0.87871792        nan 0.82096485        nan 0.95578994        nan\n",
      "        nan 0.95747414 0.18779667        nan 0.95206714        nan\n",
      "        nan        nan 0.91399113        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.95525752 0.05464509\n",
      " 0.96148383        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan 0.94530046 0.91553122        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best estimator for Stochastic Gradient Descent of dataset spam_assassin_lemmatized_tfidf is: \n",
      "SGDClassifier()\n",
      "SGDClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.978098417998251, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9771343052414496, 'macro_precision': 0.9841402337228715, 'macro_recall': 0.9634615384615385, 'macro_f1': 0.9729802481550893, 'roc_auc': 0.9634615384615385}, 'confusion_matrix': array([[580,   0],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.0001}, 'best_score': 0.9743930557920426}\n",
      "\n",
      "\n",
      "The best estimator for Gradient Boosting of dataset spam_assassin_lemmatized_tfidf is: \n",
      "GradientBoostingClassifier(max_depth=7, min_samples_leaf=4, min_samples_split=5,\n",
      "                           n_estimators=200)\n",
      "GradientBoostingClassifier classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9726190476190476, 'weighted_precision': 0.9734295865395357, 'wighted_recall': 0.9726190476190476, 'weighted_f1': 0.9722863330790447, 'macro_precision': 0.9796051211718266, 'macro_recall': 0.9568302387267904, 'macro_f1': 0.9672163972313808, 'roc_auc': 0.9568302387267905}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 22, 238]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, 'best_score': 0.9580119473295874}\n",
      "\n",
      "\n",
      "The best estimator for Perceptron of dataset spam_assassin_lemmatized_tfidf is: \n",
      "Perceptron(penalty='l2', tol=1e-05)\n",
      "Perceptron classification report\n",
      "{'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9749765748044577, 'wighted_recall': 0.975, 'weighted_f1': 0.9749866818021138, 'macro_precision': 0.9712285435177002, 'macro_recall': 0.9702254641909814, 'macro_f1': 0.9707248584785888, 'roc_auc': 0.9702254641909814}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}, 'best_score': 0.9648610874623985}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_evaluate_model(spam_assassin_lemmatizing_tfidf, csv_file[\"Is_spam\"], \"spam_assassin_lemmatized_tfidf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b78aa3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'dataset': 'spam_assassin_stemming_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9821278938925998, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.9820944920324062, 'macro_precision': 0.981649069884364, 'macro_recall': 0.9764588859416445, 'macro_f1': 0.9789991249635401, 'roc_auc': 0.9764588859416448}, 'confusion_matrix': array([[575,   5],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9687311992735116}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.969047619047619, 'weighted_precision': 0.9691028874496616, 'wighted_recall': 0.969047619047619, 'weighted_f1': 0.9688404990331839, 'macro_precision': 0.9698397994768962, 'macro_recall': 0.9574270557029179, 'macro_f1': 0.9633172986482492, 'roc_auc': 0.9574270557029178}, 'confusion_matrix': array([[573,   7],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'alpha': 1.0, 'fit_prior': False}, 'best_score': 0.9711174726147909}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9619047619047619, 'weighted_precision': 0.9627450037148095, 'wighted_recall': 0.9619047619047619, 'weighted_f1': 0.9613692033046872, 'macro_precision': 0.9683466157817937, 'macro_recall': 0.9427055702917773, 'macro_f1': 0.9542284219703576, 'roc_auc': 0.9427055702917772}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 28, 232]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9684381917248425}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9797619047619047, 'weighted_precision': 0.979827637465338, 'wighted_recall': 0.9797619047619047, 'weighted_f1': 0.9796615882018462, 'macro_precision': 0.9809962188597054, 'macro_recall': 0.971551724137931, 'macro_f1': 0.9760947771775432, 'roc_auc': 0.9715517241379309}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9746871275327771}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9345238095238095, 'weighted_precision': 0.9340953564349322, 'wighted_recall': 0.9345238095238095, 'weighted_f1': 0.9340471974743075, 'macro_precision': 0.9288220876487496, 'macro_recall': 0.9165119363395225, 'macro_f1': 0.9223152085634871, 'roc_auc': 0.9165119363395225}, 'confusion_matrix': array([[559,  21],\n",
      "       [ 34, 226]], dtype=int64), 'best_parameters': {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'entropy'}, 'best_score': 0.9309062659628808}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9678571428571429, 'weighted_precision': 0.9677822727892473, 'wighted_recall': 0.9678571428571429, 'weighted_f1': 0.9678053418746052, 'macro_precision': 0.963789202501485, 'macro_recall': 0.9608090185676392, 'macro_f1': 0.96227990373725, 'roc_auc': 0.9608090185676392}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 15, 245]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9642662040978489}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9785714285714285, 'weighted_precision': 0.9785930245113919, 'wighted_recall': 0.9785714285714285, 'weighted_f1': 0.9784774033757339, 'macro_precision': 0.9790249433106576, 'macro_recall': 0.9706896551724138, 'macro_f1': 0.9747163955479452, 'roc_auc': 0.9706896551724139}, 'confusion_matrix': array([[575,   5],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9740936630909813}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.8630952380952381, 'weighted_precision': 0.8994506814982661, 'wighted_recall': 0.8630952380952381, 'weighted_f1': 0.8677824418867074, 'macro_precision': 0.8440519105984139, 'macro_recall': 0.8955570291777188, 'macro_f1': 0.8534976303317536, 'roc_auc': 0.8955570291777188}, 'confusion_matrix': array([[470, 110],\n",
      "       [  5, 255]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.8156659713945174}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9666666666666667, 'weighted_precision': 0.9672222222222221, 'wighted_recall': 0.9666666666666667, 'weighted_f1': 0.9662824858757062, 'macro_precision': 0.9716666666666667, 'macro_recall': 0.9503978779840849, 'macro_f1': 0.960135593220339, 'roc_auc': 0.9503978779840848}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 24, 236]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'log_loss', 'learning_rate': 'optimal', 'alpha': 0.01}, 'best_score': 0.9708180799137295}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9785714285714285, 'weighted_precision': 0.9790366691290885, 'wighted_recall': 0.9785714285714285, 'weighted_f1': 0.978377065111759, 'macro_precision': 0.9836890747056882, 'macro_recall': 0.9664456233421751, 'macro_f1': 0.9744897959183674, 'roc_auc': 0.9664456233421752}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.964861442193087}, {'dataset': 'spam_assassin_stemming_countvec', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9654761904761905, 'weighted_precision': 0.9654460238828168, 'wighted_recall': 0.9654761904761905, 'weighted_f1': 0.9652652962386051, 'macro_precision': 0.9650072370701078, 'macro_recall': 0.9537798408488064, 'macro_f1': 0.9591301911452104, 'roc_auc': 0.9537798408488064}, 'confusion_matrix': array([[571,   9],\n",
      "       [ 20, 240]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}, 'best_score': 0.9666485754015551}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.9773371649518776, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9773444998376851, 'macro_precision': 0.9750018354012187, 'macro_recall': 0.971949602122016, 'macro_f1': 0.9734562285558426, 'roc_auc': 0.971949602122016}, 'confusion_matrix': array([[572,   8],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9734962966116125}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.969047619047619, 'weighted_precision': 0.9689614310156622, 'wighted_recall': 0.969047619047619, 'weighted_f1': 0.9689466004714518, 'macro_precision': 0.9666630834968155, 'macro_recall': 0.9606100795755967, 'macro_f1': 0.9635589430758655, 'roc_auc': 0.9606100795755967}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 16, 244]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9711188915375446}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9619047619047619, 'weighted_precision': 0.9627450037148095, 'wighted_recall': 0.9619047619047619, 'weighted_f1': 0.9613692033046872, 'macro_precision': 0.9683466157817937, 'macro_recall': 0.9427055702917773, 'macro_f1': 0.9542284219703576, 'roc_auc': 0.9427055702917772}, 'confusion_matrix': array([[576,   4],\n",
      "       [ 28, 232]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9684381917248425}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9823257254301228, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.98203377391652, 'macro_precision': 0.9849856277903493, 'macro_recall': 0.9732758620689654, 'macro_f1': 0.9788604436957985, 'roc_auc': 0.9732758620689654}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 13, 247]], dtype=int64), 'best_parameters': {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.974092598898916}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9261904761904762, 'weighted_precision': 0.9261904761904762, 'wighted_recall': 0.9261904761904762, 'weighted_f1': 0.9261904761904762, 'macro_precision': 0.9136604774535808, 'macro_recall': 0.9136604774535808, 'macro_f1': 0.9136604774535808, 'roc_auc': 0.9136604774535808}, 'confusion_matrix': array([[549,  31],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}, 'best_score': 0.9204913729496565}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9761904761904762, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9760860037508153, 'macro_precision': 0.9761904761904762, 'macro_recall': 0.9679045092838197, 'macro_f1': 0.9719071061643836, 'roc_auc': 0.9679045092838195}, 'confusion_matrix': array([[574,   6],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 200}, 'best_score': 0.9574124524660877}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845220139337786, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844818930947521, 'macro_precision': 0.9844645550527904, 'macro_recall': 0.9792440318302387, 'macro_f1': 0.9817992416350682, 'roc_auc': 0.9792440318302388}, 'confusion_matrix': array([[576,   4],\n",
      "       [  9, 251]], dtype=int64), 'best_parameters': {'C': 0.1, 'penalty': None, 'solver': 'saga'}, 'best_score': 0.979155315284636}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.5607142857142857, 'weighted_precision': 0.8184192595957303, 'wighted_recall': 0.5607142857142857, 'weighted_f1': 0.5494191544640991, 'macro_precision': 0.7066772655007949, 'macro_recall': 0.681896551724138, 'macro_f1': 0.5592143902366187, 'roc_auc': 0.681896551724138}, 'confusion_matrix': array([[211, 369],\n",
      "       [  0, 260]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.5175761961518816}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9767827692728878, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9759455185966459, 'macro_precision': 0.9820475966721026, 'macro_recall': 0.9625994694960213, 'macro_f1': 0.9715907169285507, 'roc_auc': 0.9625994694960213}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.0001}, 'best_score': 0.97260698677564}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9754775247982022, 'wighted_recall': 0.975, 'weighted_f1': 0.9747580785465627, 'macro_precision': 0.9799718758401059, 'macro_recall': 0.9617374005305039, 'macro_f1': 0.9702042629524468, 'roc_auc': 0.961737400530504}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.958606830694137}, {'dataset': 'spam_assassin_stemmed_tfidf', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.9678571428571429, 'weighted_precision': 0.9677822727892473, 'wighted_recall': 0.9678571428571429, 'weighted_f1': 0.9678053418746052, 'macro_precision': 0.963789202501485, 'macro_recall': 0.9608090185676392, 'macro_f1': 0.96227990373725, 'roc_auc': 0.9608090185676392}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 15, 245]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}, 'best_score': 0.9645641778761563}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845669600872919, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844646367895364, 'macro_precision': 0.985553258681175, 'macro_recall': 0.9781830238726791, 'macro_f1': 0.9817595975084814, 'roc_auc': 0.9781830238726792}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, 'best_score': 0.9726041489301323}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9738095238095238, 'weighted_precision': 0.9741825545269267, 'wighted_recall': 0.9738095238095238, 'weighted_f1': 0.9735719684699279, 'macro_precision': 0.9779128617009571, 'macro_recall': 0.9608753315649867, 'macro_f1': 0.9688208616780047, 'roc_auc': 0.9608753315649867}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'alpha': 0.5, 'fit_prior': False}, 'best_score': 0.972011039219025}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9595238095238096, 'weighted_precision': 0.9607923364445596, 'wighted_recall': 0.9595238095238096, 'weighted_f1': 0.9588490401498532, 'macro_precision': 0.9680410617059891, 'macro_recall': 0.9377984084880637, 'macro_f1': 0.9511373901617804, 'roc_auc': 0.9377984084880637}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9654612917872751}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9821428571428571, 'weighted_precision': 0.9824455743067617, 'wighted_recall': 0.9821428571428571, 'weighted_f1': 0.9820128720384474, 'macro_precision': 0.9861713240163581, 'macro_recall': 0.9722148541114058, 'macro_f1': 0.9788132386991328, 'roc_auc': 0.9722148541114058}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9752834298200806}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9273809523809524, 'weighted_precision': 0.9271739810980689, 'wighted_recall': 0.9273809523809524, 'weighted_f1': 0.9272639205315152, 'macro_precision': 0.9161355126776167, 'macro_recall': 0.9134615384615384, 'macro_f1': 0.9147805232582312, 'roc_auc': 0.9134615384615384}, 'confusion_matrix': array([[551,  29],\n",
      "       [ 32, 228]], dtype=int64), 'best_parameters': {'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 30, 'criterion': 'gini'}, 'best_score': 0.9172154350417163}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9630952380952381, 'weighted_precision': 0.9629697142844318, 'wighted_recall': 0.9630952380952381, 'weighted_f1': 0.9629541338827408, 'macro_precision': 0.9601005986088573, 'macro_recall': 0.9531167108753316, 'macro_f1': 0.9565036555971477, 'roc_auc': 0.9531167108753316}, 'confusion_matrix': array([[568,  12],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 100}, 'best_score': 0.9624772972359386}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9845669600872919, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844646367895364, 'macro_precision': 0.985553258681175, 'macro_recall': 0.9781830238726791, 'macro_f1': 0.9817595975084814, 'roc_auc': 0.9781830238726792}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 10, 250]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}, 'best_score': 0.9755814035983881}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.844047619047619, 'weighted_precision': 0.8913206123214636, 'wighted_recall': 0.844047619047619, 'weighted_f1': 0.8497148853167455, 'macro_precision': 0.8298272877376007, 'macro_recall': 0.8828249336870027, 'macro_f1': 0.8349707779499123, 'roc_auc': 0.8828249336870027}, 'confusion_matrix': array([[453, 127],\n",
      "       [  4, 256]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.8028626766558828}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9761904761904762, 'weighted_precision': 0.9767827692728878, 'wighted_recall': 0.9761904761904762, 'weighted_f1': 0.9759455185966459, 'macro_precision': 0.9820475966721026, 'macro_recall': 0.9625994694960213, 'macro_f1': 0.9715907169285507, 'roc_auc': 0.9625994694960213}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.01}, 'best_score': 0.9758786679153187}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.9777453838678329, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9771894028308606, 'macro_precision': 0.9816326530612245, 'macro_recall': 0.9655835543766578, 'macro_f1': 0.9731030124289024, 'roc_auc': 0.9655835543766578}, 'confusion_matrix': array([[578,   2],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 200}, 'best_score': 0.9645613400306488}, {'dataset': 'spam_assassin_lemmatized_countvec', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9756613719962038, 'wighted_recall': 0.975, 'weighted_f1': 0.9747273900037075, 'macro_precision': 0.9812308203852895, 'macro_recall': 0.9606763925729443, 'macro_f1': 0.9701360637503619, 'roc_auc': 0.9606763925729443}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 20, 240]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}, 'best_score': 0.9603911260570974}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'SVM', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9749765748044577, 'wighted_recall': 0.975, 'weighted_f1': 0.9749866818021138, 'macro_precision': 0.9712285435177002, 'macro_recall': 0.9702254641909814, 'macro_f1': 0.9707248584785888, 'roc_auc': 0.9702254641909814}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}, 'best_score': 0.9758779584539418}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Multinomial Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9726190476190476, 'weighted_precision': 0.9725514137278843, 'wighted_recall': 0.9726190476190476, 'weighted_f1': 0.9725448877830226, 'macro_precision': 0.9703871292106586, 'macro_recall': 0.9653183023872679, 'macro_f1': 0.9677986582774282, 'roc_auc': 0.965318302387268}, 'confusion_matrix': array([[571,   9],\n",
      "       [ 14, 246]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9729060247460128}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Bernoulli Naive Bayes', 'type': 'grid_search', 'metrics': {'accuracy': 0.9595238095238096, 'weighted_precision': 0.9607923364445596, 'wighted_recall': 0.9595238095238096, 'weighted_f1': 0.9588490401498532, 'macro_precision': 0.9680410617059891, 'macro_recall': 0.9377984084880637, 'macro_f1': 0.9511373901617804, 'roc_auc': 0.9377984084880637}, 'confusion_matrix': array([[577,   3],\n",
      "       [ 31, 229]], dtype=int64), 'best_parameters': {'alpha': 0.1, 'fit_prior': False}, 'best_score': 0.9654612917872751}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Random Forest', 'type': 'grid_search', 'metrics': {'accuracy': 0.9845238095238096, 'weighted_precision': 0.9847371113654521, 'wighted_recall': 0.9845238095238096, 'weighted_f1': 0.9844292707276506, 'macro_precision': 0.9878396836075265, 'macro_recall': 0.9760610079575598, 'macro_f1': 0.9816790512030253, 'roc_auc': 0.9760610079575599}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 12, 248]], dtype=int64), 'best_parameters': {'n_estimators': 50, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None}, 'best_score': 0.9740911799761621}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Decision Tree', 'type': 'grid_search', 'metrics': {'accuracy': 0.9321428571428572, 'weighted_precision': 0.9330069113173171, 'wighted_recall': 0.9321428571428572, 'weighted_f1': 0.9324547945604019, 'macro_precision': 0.9176459482158088, 'macro_recall': 0.9253978779840849, 'macro_f1': 0.9213636863810379, 'roc_auc': 0.9253978779840847}, 'confusion_matrix': array([[547,  33],\n",
      "       [ 24, 236]], dtype=int64), 'best_parameters': {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': None, 'criterion': 'gini'}, 'best_score': 0.9189983114819229}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'AdaBoost', 'type': 'grid_search', 'metrics': {'accuracy': 0.9666666666666667, 'weighted_precision': 0.9665645463259074, 'wighted_recall': 0.9666666666666667, 'weighted_f1': 0.9665578774307942, 'macro_precision': 0.9638413372389885, 'macro_recall': 0.9578249336870026, 'macro_f1': 0.960755784850932, 'roc_auc': 0.9578249336870027}, 'confusion_matrix': array([[569,  11],\n",
      "       [ 17, 243]], dtype=int64), 'best_parameters': {'learning_rate': 1.0, 'n_estimators': 100}, 'best_score': 0.9568196974856689}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Logistic Regression', 'type': 'grid_search', 'metrics': {'accuracy': 0.9904761904761905, 'weighted_precision': 0.9905333932234581, 'wighted_recall': 0.9904761904761905, 'weighted_f1': 0.9904451078373697, 'macro_precision': 0.9920587998172583, 'macro_recall': 0.9856763925729444, 'macro_f1': 0.9887873671002663, 'roc_auc': 0.9856763925729444}, 'confusion_matrix': array([[579,   1],\n",
      "       [  7, 253]], dtype=int64), 'best_parameters': {'C': 1, 'penalty': None, 'solver': 'saga'}, 'best_score': 0.9809413843010387}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'K-nearest Neighbors', 'type': 'grid_search', 'metrics': {'accuracy': 0.55, 'weighted_precision': 0.8166144200626959, 'wighted_recall': 0.55, 'weighted_f1': 0.5359508769131744, 'macro_precision': 0.7037617554858935, 'macro_recall': 0.6741379310344827, 'macro_f1': 0.547844314446995, 'roc_auc': 0.6741379310344828}, 'confusion_matrix': array([[202, 378],\n",
      "       [  0, 260]], dtype=int64), 'best_parameters': {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'}, 'best_score': 0.5095344514444634}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Stochastic Gradient Descent', 'type': 'grid_search', 'metrics': {'accuracy': 0.9773809523809524, 'weighted_precision': 0.978098417998251, 'wighted_recall': 0.9773809523809524, 'weighted_f1': 0.9771343052414496, 'macro_precision': 0.9841402337228715, 'macro_recall': 0.9634615384615385, 'macro_f1': 0.9729802481550893, 'roc_auc': 0.9634615384615385}, 'confusion_matrix': array([[580,   0],\n",
      "       [ 19, 241]], dtype=int64), 'best_parameters': {'penalty': 'l2', 'loss': 'hinge', 'learning_rate': 'optimal', 'alpha': 0.0001}, 'best_score': 0.9743930557920426}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Gradient Boosting', 'type': 'grid_search', 'metrics': {'accuracy': 0.9726190476190476, 'weighted_precision': 0.9734295865395357, 'wighted_recall': 0.9726190476190476, 'weighted_f1': 0.9722863330790447, 'macro_precision': 0.9796051211718266, 'macro_recall': 0.9568302387267904, 'macro_f1': 0.9672163972313808, 'roc_auc': 0.9568302387267905}, 'confusion_matrix': array([[579,   1],\n",
      "       [ 22, 238]], dtype=int64), 'best_parameters': {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 4, 'min_samples_split': 5, 'n_estimators': 200}, 'best_score': 0.9580119473295874}, {'dataset': 'spam_assassin_lemmatized_tfidf', 'model': 'Perceptron', 'type': 'grid_search', 'metrics': {'accuracy': 0.975, 'weighted_precision': 0.9749765748044577, 'wighted_recall': 0.975, 'weighted_f1': 0.9749866818021138, 'macro_precision': 0.9712285435177002, 'macro_recall': 0.9702254641909814, 'macro_f1': 0.9707248584785888, 'roc_auc': 0.9702254641909814}, 'confusion_matrix': array([[570,  10],\n",
      "       [ 11, 249]], dtype=int64), 'best_parameters': {'alpha': 0.0001, 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}, 'best_score': 0.9648610874623985}]\n"
     ]
    }
   ],
   "source": [
    "print(metric_results)\n",
    "\n",
    "def convert(dic):\n",
    "    dic[\"confusion_matrix\"] = dic[\"confusion_matrix\"].tolist()\n",
    "    return dic\n",
    "\n",
    "metric_results = list(map(convert, metric_results))\n",
    "\n",
    "add_to_json_array(\"./spam_assassin_grid_classification_report.json\", metric_results, mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
